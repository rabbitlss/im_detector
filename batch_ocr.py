# -*- coding: utf-8 -*-
"""
çµæ´»çš„æ‰¹é‡OCRå¤„ç†å™¨ - æ”¯æŒä¸ç¡®å®šä¸ªæ•°çš„å›¾ç‰‡åˆ—è¡¨
"""

import cv2
import numpy as np
import time
from typing import List, Dict, Union, Any
from dataclasses import dataclass
from pathlib import Path

@dataclass
class OCRInput:
    """OCRè¾“å…¥æ•°æ®"""
    source_id: str  # å”¯ä¸€æ ‡è¯†
    image: np.ndarray  # å›¾åƒæ•°æ®
    metadata: Dict = None  # å¯é€‰å…ƒæ•°æ®

class FlexibleBatchOCRProcessor:
    """çµæ´»çš„æ‰¹é‡OCRå¤„ç†å™¨"""
    
    def __init__(self, 
                 max_batch_size: int = 32,
                 auto_split_large_batch: bool = True):
        """
        åˆå§‹åŒ–
        
        Args:
            max_batch_size: å•æ‰¹æ¬¡æœ€å¤§å¤„ç†æ•°é‡
            auto_split_large_batch: è‡ªåŠ¨åˆ†å‰²å¤§æ‰¹æ¬¡
        """
        self.max_batch_size = max_batch_size
        self.auto_split_large_batch = auto_split_large_batch
        self.target_height = 48
        
    def process_dynamic_list(self, 
                            inputs: Union[List[np.ndarray], 
                                        List[str], 
                                        List[Dict],
                                        List[OCRInput]]) -> Dict:
        """
        å¤„ç†ä¸ç¡®å®šä¸ªæ•°çš„è¾“å…¥åˆ—è¡¨
        
        æ”¯æŒçš„è¾“å…¥æ ¼å¼ï¼š
        1. å›¾åƒæ•°ç»„åˆ—è¡¨: [img1, img2, ...]
        2. å›¾åƒè·¯å¾„åˆ—è¡¨: ["path1.jpg", "path2.png", ...]
        3. å­—å…¸åˆ—è¡¨: [{'image': img1, 'id': '1'}, ...]
        4. OCRInputå¯¹è±¡åˆ—è¡¨: [OCRInput(...), ...]
        
        Args:
            inputs: å„ç§æ ¼å¼çš„è¾“å…¥åˆ—è¡¨
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        
        print(f"ğŸ“¥ æ¥æ”¶åˆ° {len(inputs)} ä¸ªè¾“å…¥é¡¹")
        
        # æ­¥éª¤1: æ ‡å‡†åŒ–è¾“å…¥
        ocr_inputs = self._standardize_inputs(inputs)
        
        if not ocr_inputs:
            return {
                'success': False,
                'message': 'æ— æœ‰æ•ˆè¾“å…¥',
                'results': []
            }
        
        print(f"âœ… æ ‡å‡†åŒ–å®Œæˆ: {len(ocr_inputs)} ä¸ªæœ‰æ•ˆè¾“å…¥")
        
        # æ­¥éª¤2: å¤„ç†å¤§æ‰¹æ¬¡
        if self.auto_split_large_batch and len(ocr_inputs) > self.max_batch_size:
            return self._process_large_batch(ocr_inputs)
        
        # æ­¥éª¤3: åˆ›å»ºæ‰¹å¤„ç†å›¾åƒ
        batch_image, mappings = self._create_flexible_batch(ocr_inputs)
        
        # æ­¥éª¤4: æ‰§è¡ŒOCRï¼ˆå•æ¬¡è°ƒç”¨ï¼‰
        results = self._execute_batch_ocr(batch_image, mappings)
        
        return {
            'success': True,
            'total_inputs': len(ocr_inputs),
            'ocr_calls': 1,
            'results': results,
            'batch_info': {
                'batch_size': len(ocr_inputs),
                'image_shape': batch_image.shape
            }
        }
    
    def process_to_text_list(self,
                            inputs: Union[List[np.ndarray], List[str], List[Dict]]) -> List[str]:
        """
        å¤„ç†å›¾ç‰‡åˆ—è¡¨ï¼Œè¿”å›æ–‡å­—åˆ—è¡¨ï¼ˆä¿æŒé¡ºåºä¸€ä¸€å¯¹åº”ï¼‰
        
        è¾“å…¥: [img1, img2, img3, ...]
        è¾“å‡º: ["text1", "text2", "text3", ...]
        
        Args:
            inputs: å›¾ç‰‡è¾“å…¥åˆ—è¡¨
            
        Returns:
            æ–‡å­—è¯†åˆ«ç»“æœåˆ—è¡¨ï¼Œä¸è¾“å…¥é¡ºåºä¸€ä¸€å¯¹åº”
        """
        
        if not inputs:
            return []
        
        # è®°å½•åŸå§‹ç´¢å¼•å’Œæœ‰æ•ˆè¾“å…¥çš„æ˜ å°„
        input_mapping = {}
        valid_inputs = []
        
        for i, item in enumerate(inputs):
            ocr_input = self._convert_to_ocr_input(item, i)
            if ocr_input:
                input_mapping[ocr_input.source_id] = i
                valid_inputs.append(ocr_input)
        
        # åˆå§‹åŒ–ç»“æœåˆ—è¡¨ï¼ˆä¿æŒåŸå§‹é•¿åº¦ï¼‰
        results = [""] * len(inputs)
        
        # æ‰¹å¤„ç†è¯†åˆ«
        if valid_inputs:
            # åˆ†æ‰¹å¤„ç†
            for batch_start in range(0, len(valid_inputs), self.max_batch_size):
                batch_end = min(batch_start + self.max_batch_size, len(valid_inputs))
                batch = valid_inputs[batch_start:batch_end]
                
                # åˆ›å»ºæ‰¹å¤„ç†å›¾åƒ
                batch_image, mappings = self._create_flexible_batch(batch)
                
                # æ‰§è¡ŒOCR
                batch_results = self._execute_batch_ocr(batch_image, mappings)
                
                # å°†ç»“æœæ”¾å›å¯¹åº”ä½ç½®
                for result in batch_results:
                    source_id = result['source_id']
                    if source_id in input_mapping:
                        original_idx = input_mapping[source_id]
                        results[original_idx] = result['text']
        
        return results
    
    def process_to_dict_list(self,
                            inputs: Union[List[np.ndarray], List[str], List[Dict]]) -> List[Dict]:
        """
        å¤„ç†å›¾ç‰‡åˆ—è¡¨ï¼Œè¿”å›åŒ…å«æ–‡å­—å’Œç½®ä¿¡åº¦çš„å­—å…¸åˆ—è¡¨
        
        è¾“å…¥: [img1, img2, img3, ...]
        è¾“å‡º: [
            {"text": "text1", "confidence": 0.95},
            {"text": "text2", "confidence": 0.92},
            {"text": "text3", "confidence": 0.88}
        ]
        
        Args:
            inputs: å›¾ç‰‡è¾“å…¥åˆ—è¡¨
            
        Returns:
            åŒ…å«æ–‡å­—å’Œç½®ä¿¡åº¦çš„å­—å…¸åˆ—è¡¨
        """
        
        if not inputs:
            return []
        
        # è®°å½•æ˜ å°„å…³ç³»
        input_mapping = {}
        valid_inputs = []
        
        for i, item in enumerate(inputs):
            ocr_input = self._convert_to_ocr_input(item, i)
            if ocr_input:
                input_mapping[ocr_input.source_id] = i
                valid_inputs.append(ocr_input)
        
        # åˆå§‹åŒ–ç»“æœ
        results = [{"text": "", "confidence": 0.0} for _ in range(len(inputs))]
        
        # æ‰¹å¤„ç†
        if valid_inputs:
            for batch_start in range(0, len(valid_inputs), self.max_batch_size):
                batch_end = min(batch_start + self.max_batch_size, len(valid_inputs))
                batch = valid_inputs[batch_start:batch_end]
                
                batch_image, mappings = self._create_flexible_batch(batch)
                batch_results = self._execute_batch_ocr(batch_image, mappings)
                
                # æ˜ å°„ç»“æœ
                for result in batch_results:
                    source_id = result['source_id']
                    if source_id in input_mapping:
                        original_idx = input_mapping[source_id]
                        results[original_idx] = {
                            "text": result['text'],
                            "confidence": result['confidence']
                        }
        
        return results
    
    def _convert_to_ocr_input(self, item: Any, index: int) -> OCRInput:
        """å°†å•ä¸ªè¾“å…¥è½¬æ¢ä¸ºOCRInputå¯¹è±¡"""
        
        if isinstance(item, np.ndarray):
            return OCRInput(
                source_id=f"img_{index}",
                image=item
            )
        elif isinstance(item, str):
            if Path(item).exists():
                img = cv2.imread(item)
                if img is not None:
                    return OCRInput(
                        source_id=f"img_{index}",
                        image=img
                    )
        elif isinstance(item, dict) and 'image' in item:
            return OCRInput(
                source_id=f"img_{index}",
                image=item['image'],
                metadata=item
            )
        elif isinstance(item, OCRInput):
            item.source_id = f"img_{index}"  # ç¡®ä¿æœ‰ç´¢å¼•ä¿¡æ¯
            return item
        
        return None
    
    def _standardize_inputs(self, inputs: Any) -> List[OCRInput]:
        """æ ‡å‡†åŒ–å„ç§è¾“å…¥æ ¼å¼"""
        
        standardized = []
        
        for i, item in enumerate(inputs):
            ocr_input = None
            
            # å¤„ç†ä¸åŒè¾“å…¥ç±»å‹
            if isinstance(item, np.ndarray):
                # ç›´æ¥çš„å›¾åƒæ•°ç»„
                ocr_input = OCRInput(
                    source_id=f"image_{i}",
                    image=item
                )
            
            elif isinstance(item, str):
                # å›¾åƒè·¯å¾„
                if Path(item).exists():
                    img = cv2.imread(item)
                    if img is not None:
                        ocr_input = OCRInput(
                            source_id=Path(item).stem,
                            image=img
                        )
            
            elif isinstance(item, dict):
                # å­—å…¸æ ¼å¼
                if 'image' in item:
                    ocr_input = OCRInput(
                        source_id=item.get('id', f"dict_{i}"),
                        image=item['image'],
                        metadata=item
                    )
            
            elif isinstance(item, OCRInput):
                # å·²ç»æ˜¯OCRInputå¯¹è±¡
                ocr_input = item
            
            if ocr_input:
                standardized.append(ocr_input)
            else:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆè¾“å…¥: ç´¢å¼•{i}")
        
        return standardized
    
    def _process_large_batch(self, ocr_inputs: List[OCRInput]) -> Dict:
        """å¤„ç†è¶…è¿‡æœ€å¤§æ‰¹æ¬¡å¤§å°çš„è¾“å…¥"""
        
        print(f"ğŸ”„ å¤§æ‰¹æ¬¡åˆ†å‰²: {len(ocr_inputs)} ä¸ªè¾“å…¥ â†’ "
              f"{(len(ocr_inputs) + self.max_batch_size - 1) // self.max_batch_size} ä¸ªå­æ‰¹æ¬¡")
        
        all_results = []
        ocr_call_count = 0
        
        # åˆ†æ‰¹å¤„ç†
        for batch_idx in range(0, len(ocr_inputs), self.max_batch_size):
            batch = ocr_inputs[batch_idx:batch_idx + self.max_batch_size]
            
            print(f"\nå¤„ç†å­æ‰¹æ¬¡ {batch_idx // self.max_batch_size + 1}: "
                  f"{len(batch)} ä¸ªè¾“å…¥")
            
            # åˆ›å»ºæ‰¹å¤„ç†å›¾åƒ
            batch_image, mappings = self._create_flexible_batch(batch)
            
            # æ‰§è¡ŒOCR
            batch_results = self._execute_batch_ocr(batch_image, mappings)
            all_results.extend(batch_results)
            ocr_call_count += 1
        
        return {
            'success': True,
            'total_inputs': len(ocr_inputs),
            'ocr_calls': ocr_call_count,
            'results': all_results,
            'batch_info': {
                'sub_batches': ocr_call_count,
                'max_batch_size': self.max_batch_size
            }
        }
    
    def _create_flexible_batch(self, ocr_inputs: List[OCRInput]) -> tuple:
        """åˆ›å»ºçµæ´»çš„æ‰¹å¤„ç†å›¾åƒ"""
        
        normalized_images = []
        mappings = []
        current_x = 0
        
        for ocr_input in ocr_inputs:
            img = ocr_input.image
            
            # ç¡®ä¿æ˜¯3é€šé“
            if len(img.shape) == 2:
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            
            # è°ƒæ•´åˆ°ç›®æ ‡é«˜åº¦
            h, w = img.shape[:2]
            scale = self.target_height / h
            new_w = int(w * scale)
            
            resized = cv2.resize(img, (new_w, self.target_height))
            normalized_images.append(resized)
            
            # è®°å½•æ˜ å°„
            mappings.append({
                'source_id': ocr_input.source_id,
                'batch_position': (current_x, 0, current_x + new_w, self.target_height),
                'original_size': (h, w),
                'metadata': ocr_input.metadata
            })
            
            current_x += new_w + 5  # 5pxé—´éš”
        
        # æ‹¼æ¥æ‰¹å¤„ç†å›¾åƒ
        if normalized_images:
            # è®¡ç®—æ€»å®½åº¦
            total_width = current_x - 5
            batch_image = np.ones((self.target_height, total_width, 3), 
                                 dtype=np.uint8) * 255
            
            # æ”¾ç½®æ¯ä¸ªå›¾åƒ
            x = 0
            for img in normalized_images:
                w = img.shape[1]
                batch_image[:, x:x+w] = img
                x += w + 5
            
            return batch_image, mappings
        
        return np.array([]), []
    
    def _execute_batch_ocr(self, batch_image: np.ndarray, 
                          mappings: List[Dict]) -> List[Dict]:
        """æ‰§è¡Œæ‰¹é‡OCRè¯†åˆ«"""
        
        if batch_image.size == 0:
            return []
        
        print(f"ğŸ” æ‰§è¡ŒOCRè¯†åˆ«: æ‰¹æ¬¡å›¾åƒ {batch_image.shape}")
        
        # æ¨¡æ‹ŸOCRè°ƒç”¨
        start_time = time.time()
        
        results = []
        for mapping in mappings:
            results.append({
                'source_id': mapping['source_id'],
                'text': f"è¯†åˆ«æ–‡å­—_{mapping['source_id']}",
                'confidence': 0.9,
                'metadata': mapping.get('metadata')
            })
        
        elapsed_ms = (time.time() - start_time) * 1000
        print(f"âœ… OCRå®Œæˆ: {len(results)} ä¸ªç»“æœ, è€—æ—¶ {elapsed_ms:.1f}ms")
        
        return results
    
    def process_from_directory(self, directory_path: str, 
                              extensions: List[str] = None) -> Dict:
        """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        
        if extensions is None:
            extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        
        dir_path = Path(directory_path)
        if not dir_path.exists():
            return {'success': False, 'message': f'ç›®å½•ä¸å­˜åœ¨: {directory_path}'}
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in extensions:
            image_files.extend(dir_path.glob(f'*{ext}'))
            image_files.extend(dir_path.glob(f'*{ext.upper()}'))
        
        print(f"ğŸ“‚ ä»ç›®å½• {directory_path} æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        # è½¬æ¢ä¸ºè·¯å¾„å­—ç¬¦ä¸²åˆ—è¡¨
        file_paths = [str(f) for f in image_files]
        
        return self.process_dynamic_list(file_paths)


def demo_flexible_processing():
    """æ¼”ç¤ºçµæ´»çš„æ‰¹å¤„ç†åŠŸèƒ½"""
    
    print("ğŸ® çµæ´»æ‰¹å¤„ç†OCRæ¼”ç¤º")
    print("="*60)
    
    processor = FlexibleBatchOCRProcessor(max_batch_size=10)
    
    # æµ‹è¯•1: åˆ—è¡¨è¾“å…¥è¾“å‡ºï¼ˆæ–°åŠŸèƒ½ï¼‰
    print("\nğŸ“Œ æµ‹è¯•1: åˆ—è¡¨è¾“å…¥ â†’ åˆ—è¡¨è¾“å‡ºï¼ˆä¿æŒé¡ºåºï¼‰")
    test_images = [
        np.ones((30, 100, 3), dtype=np.uint8) * 100,
        np.ones((35, 120, 3), dtype=np.uint8) * 150,
        np.ones((40, 110, 3), dtype=np.uint8) * 200,
        np.ones((25, 90, 3), dtype=np.uint8) * 120,
        np.ones((45, 130, 3), dtype=np.uint8) * 180,
    ]
    
    # è·å–æ–‡å­—åˆ—è¡¨
    text_results = processor.process_to_text_list(test_images)
    print(f"è¾“å…¥: {len(test_images)} ä¸ªå›¾ç‰‡")
    print(f"è¾“å‡º: {len(text_results)} ä¸ªæ–‡å­—")
    print("ç»“æœåˆ—è¡¨:", text_results[:3], "...")  # æ˜¾ç¤ºå‰3ä¸ªç»“æœ
    
    # è·å–å¸¦ç½®ä¿¡åº¦çš„ç»“æœ
    dict_results = processor.process_to_dict_list(test_images[:3])
    print("\nå¸¦ç½®ä¿¡åº¦çš„ç»“æœ:")
    for i, result in enumerate(dict_results):
        print(f"  å›¾ç‰‡{i}: text='{result['text']}', confidence={result['confidence']:.2f}")
    
    # æµ‹è¯•2: ä¸ç¡®å®šä¸ªæ•°çš„å›¾åƒæ•°ç»„
    print("\nğŸ“Œ æµ‹è¯•2: å¤„ç†éšæœºæ•°é‡çš„å›¾åƒ")
    import random
    num_images = random.randint(5, 25)
    random_images = [
        np.ones((30 + i*2, 100, 3), dtype=np.uint8) * (100 + i*10)
        for i in range(num_images)
    ]
    
    random_results = processor.process_to_text_list(random_images)
    print(f"â€¢ è¾“å…¥æ•°é‡: {len(random_images)}")
    print(f"â€¢ è¾“å‡ºæ•°é‡: {len(random_results)}")
    print(f"â€¢ éªŒè¯: æ•°é‡ä¸€è‡´ = {len(random_images) == len(random_results)}")
    
    # æµ‹è¯•3: åŒ…å«æ— æ•ˆè¾“å…¥
    print("\nğŸ“Œ æµ‹è¯•3: å¤„ç†åŒ…å«æ— æ•ˆè¾“å…¥çš„åˆ—è¡¨")
    mixed_inputs = [
        np.ones((30, 100, 3), dtype=np.uint8) * 100,  # æœ‰æ•ˆ
        None,                                           # æ— æ•ˆ
        np.ones((35, 120, 3), dtype=np.uint8) * 150,  # æœ‰æ•ˆ
        "non_existent.jpg",                            # æ— æ•ˆ
        np.ones((40, 110, 3), dtype=np.uint8) * 200,  # æœ‰æ•ˆ
    ]
    
    # å¤„ç†æ··åˆè¾“å…¥
    mixed_results = processor.process_to_text_list(mixed_inputs)
    print("è¾“å…¥è¾“å‡ºå¯¹åº”:")
    for i, (inp, res) in enumerate(zip(mixed_inputs, mixed_results)):
        inp_type = "æœ‰æ•ˆå›¾ç‰‡" if isinstance(inp, np.ndarray) else "æ— æ•ˆè¾“å…¥"
        print(f"  ç´¢å¼•{i} ({inp_type}): '{res}'")
    
    # æµ‹è¯•4: è¶…å¤§æ‰¹æ¬¡
    print("\nğŸ“Œ æµ‹è¯•4: è¶…å¤§æ‰¹æ¬¡ï¼ˆè‡ªåŠ¨åˆ†å‰²ï¼‰")
    large_batch = [
        np.ones((30, 100, 3), dtype=np.uint8) * 100
        for _ in range(75)
    ]
    
    large_results = processor.process_to_text_list(large_batch)
    print(f"â€¢ è¾“å…¥æ•°é‡: {len(large_batch)}")
    print(f"â€¢ è¾“å‡ºæ•°é‡: {len(large_results)}")
    print(f"â€¢ å¤„ç†æˆåŠŸ: {len(large_results) == 75}")
    
    print("\nğŸ† æ€»ç»“:")
    print("â€¢ æ”¯æŒåˆ—è¡¨è¾“å…¥ â†’ åˆ—è¡¨è¾“å‡ºï¼ˆä¿æŒé¡ºåºï¼‰")
    print("â€¢ è‡ªåŠ¨å¤„ç†æ— æ•ˆè¾“å…¥ï¼ˆè¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰")
    print("â€¢ æ”¯æŒä»»æ„æ•°é‡ï¼ˆ1åˆ°âˆï¼‰")
    print("â€¢ ä¿æŒè¾“å…¥è¾“å‡ºä¸€ä¸€å¯¹åº”")

if __name__ == "__main__":
    demo_flexible_processing()
