# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºè„šæœ¬ï¼šå±•ç¤ºIMæ£€æµ‹å™¨çš„å®Œæ•´åŠŸèƒ½
"""

import os
import cv2
import time
from pathlib import Path
from end2end_pipeline import End2EndIMDetector


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç»“æ„"""
    print("ğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®ç»“æ„...")
    
    dirs = [
        "./data/raw_images",
        "./data/test_images", 
        "./models",
        "./results",
        "./demo_results"
    ]
    
    for dir_path in dirs:
        os.makedirs(dir_path, exist_ok=True)
        
    print("âœ… ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")
    print("\nè¯·å°†IMæˆªå›¾æ”¾å…¥ä»¥ä¸‹æ–‡ä»¶å¤¹ï¼š")
    print("  - è®­ç»ƒå›¾ç‰‡ï¼š./data/raw_images/")
    print("  - æµ‹è¯•å›¾ç‰‡ï¼š./data/test_images/")
    print("  - æ”¯æŒæ ¼å¼ï¼š.jpg, .jpeg, .png")


def check_requirements():
    """æ£€æŸ¥ç¯å¢ƒè¦æ±‚"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒè¦æ±‚...")
    
    # æ£€æŸ¥PythonåŒ…
    required_packages = {
        'torch': 'PyTorch',
        'ultralytics': 'Ultralytics YOLO',
        'opencv-python': 'OpenCV',
        'openai': 'OpenAI API',
        'numpy': 'NumPy',
        'tqdm': 'TQDM'
    }
    
    missing_packages = []
    
    for package, name in required_packages.items():
        try:
            __import__(package.replace('-', '_'))
            print(f"  âœ… {name}")
        except ImportError:
            print(f"  âŒ {name} - æœªå®‰è£…")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nè¯·å®‰è£…ç¼ºå¤±çš„åŒ…ï¼š")
        print(f"pip install {' '.join(missing_packages)}")
        return False
    
    # æ£€æŸ¥OpenAI API Key
    api_key = os.getenv('OPENAI_API_KEY')
    if api_key:
        print(f"  âœ… OpenAI API Key - å·²è®¾ç½®")
    else:
        print(f"  âš ï¸ OpenAI API Key - æœªè®¾ç½®")
        print(f"     export OPENAI_API_KEY='your-key-here'")
    
    # æ£€æŸ¥CUDA
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            print(f"  âœ… CUDA - {gpu_count} ä¸ªGPU ({gpu_name})")
        else:
            print(f"  âš ï¸ CUDA - æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPU")
    except:
        print(f"  âŒ CUDA - æ£€æŸ¥å¤±è´¥")
    
    return len(missing_packages) == 0


def demo_auto_labeling():
    """æ¼”ç¤ºè‡ªåŠ¨æ ‡æ³¨åŠŸèƒ½"""
    print("\nğŸ·ï¸ æ¼”ç¤ºï¼šGPT-4Vè‡ªåŠ¨æ ‡æ³¨")
    print("=" * 40)
    
    from auto_labeler import GPT4VAutoLabeler
    
    # æ£€æŸ¥å›¾ç‰‡
    raw_images = list(Path("./data/raw_images").glob("*.jpg"))
    if len(raw_images) == 0:
        print("âŒ æœªæ‰¾åˆ°åŸå§‹å›¾ç‰‡")
        print("è¯·å°†IMæˆªå›¾æ”¾å…¥ ./data/raw_images/ æ–‡ä»¶å¤¹")
        return False
    
    print(f"ğŸ“¸ æ‰¾åˆ° {len(raw_images)} å¼ å›¾ç‰‡")
    
    # åªæ ‡æ³¨å‰3å¼ åšæ¼”ç¤º
    demo_images = raw_images[:3]
    
    labeler = GPT4VAutoLabeler()
    
    print(f"ğŸ¤– å¼€å§‹æ ‡æ³¨ {len(demo_images)} å¼ å›¾ç‰‡ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰...")
    
    try:
        labeler.batch_labeling(
            "./data/raw_images",
            "./data/labeled_data/demo",
            max_images=len(demo_images)
        )
        
        # æ£€æŸ¥æ ‡æ³¨ç»“æœ
        labeled_images = list(Path("./data/labeled_data/demo/images").glob("*"))
        labeled_texts = list(Path("./data/labeled_data/demo/labels").glob("*.txt"))
        
        print(f"âœ… æ ‡æ³¨å®Œæˆï¼š{len(labeled_images)} å¼ å›¾ç‰‡ï¼Œ{len(labeled_texts)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        # æ˜¾ç¤ºæ ‡æ³¨å†…å®¹ç¤ºä¾‹
        if labeled_texts:
            with open(labeled_texts[0], 'r') as f:
                lines = f.readlines()
            print(f"ğŸ“„ æ ‡æ³¨ç¤ºä¾‹ ({labeled_texts[0].name}):")
            for line in lines[:3]:  # æ˜¾ç¤ºå‰3è¡Œ
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    from config import CLASS_NAMES
                    class_name = CLASS_NAMES[class_id]
                    print(f"  - {class_name}: åæ ‡ {parts[1:5]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ ‡æ³¨å¤±è´¥ï¼š{e}")
        return False


def demo_training():
    """æ¼”ç¤ºæ¨¡å‹è®­ç»ƒ"""
    print("\nğŸš‚ æ¼”ç¤ºï¼šYOLOæ¨¡å‹è®­ç»ƒ")
    print("=" * 40)
    
    # æ£€æŸ¥æ ‡æ³¨æ•°æ®
    labeled_images = list(Path("./data/labeled_data/demo/images").glob("*"))
    if len(labeled_images) == 0:
        print("âŒ æœªæ‰¾åˆ°æ ‡æ³¨æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œè‡ªåŠ¨æ ‡æ³¨æ¼”ç¤º")
        return False
    
    from yolo_trainer import YOLOTrainer
    
    trainer = YOLOTrainer()
    
    try:
        # å‡†å¤‡æ•°æ®é›†
        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®é›†...")
        dataset_config = trainer.prepare_dataset("./data/labeled_data/demo")
        
        # å¿«é€Ÿè®­ç»ƒï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
        print("ğŸƒâ€â™‚ï¸ å¿«é€Ÿè®­ç»ƒï¼ˆ10è½®ï¼Œä»…ç”¨äºæ¼”ç¤ºï¼‰...")
        model = trainer.train_model(
            dataset_config=dataset_config,
            epochs=10,  # æ¼”ç¤ºç”¨ï¼Œå®é™…éœ€è¦100+è½®
            batch_size=2,
            model_type='yolov8n'
        )
        
        # è¯„ä¼°
        print("ğŸ“ˆ è¯„ä¼°æ¨¡å‹...")
        metrics = trainer.evaluate_model()
        
        print("ğŸ“Š è®­ç»ƒç»“æœï¼š")
        for key, value in metrics.items():
            print(f"  {key}: {value:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        model_path = trainer.save_model("./models/demo_model.pt")
        print(f"ğŸ’¾ æ¼”ç¤ºæ¨¡å‹å·²ä¿å­˜ï¼š{model_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥ï¼š{e}")
        return False


def demo_detection():
    """æ¼”ç¤ºæ£€æµ‹åŠŸèƒ½"""
    print("\nğŸ” æ¼”ç¤ºï¼šIMå…ƒç´ æ£€æµ‹")
    print("=" * 40)
    
    # æ£€æŸ¥æ¨¡å‹
    model_path = "./models/demo_model.pt"
    if not os.path.exists(model_path):
        print("âŒ æ¼”ç¤ºæ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒæ¼”ç¤º")
        return False
    
    # æ£€æŸ¥æµ‹è¯•å›¾ç‰‡
    test_images = list(Path("./data/test_images").glob("*.jpg"))
    if len(test_images) == 0:
        # ä½¿ç”¨åŸå§‹å›¾ç‰‡ä½œä¸ºæµ‹è¯•
        test_images = list(Path("./data/raw_images").glob("*.jpg"))[:2]
    
    if len(test_images) == 0:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return False
    
    from im_detector import IMDetector
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = IMDetector(model_path, confidence=0.3)
    
    print(f"ğŸ¯ æµ‹è¯•æ£€æµ‹åŠŸèƒ½ï¼Œå…± {len(test_images)} å¼ å›¾ç‰‡...")
    
    for i, img_path in enumerate(test_images):
        print(f"\nğŸ“¸ æ£€æµ‹å›¾ç‰‡ {i+1}: {img_path.name}")
        
        # æ£€æµ‹
        start_time = time.time()
        result = detector.predict(str(img_path), return_image=True)
        inference_time = time.time() - start_time
        
        # æ˜¾ç¤ºç»“æœ
        detection_count = 0
        for class_name, objects in result.items():
            if class_name not in ['metadata', 'annotated_image']:
                if len(objects) > 0:
                    print(f"  âœ… {class_name}: {len(objects)} ä¸ª")
                    detection_count += len(objects)
        
        print(f"  âš¡ æ¨ç†æ—¶é—´: {inference_time*1000:.2f} ms")
        print(f"  ğŸ“Š æ£€æµ‹æ€»æ•°: {detection_count} ä¸ªå…ƒç´ ")
        
        # ä¿å­˜æ ‡æ³¨å›¾ç‰‡
        if 'annotated_image' in result and result['annotated_image'] is not None:
            output_path = f"./demo_results/detected_{i+1}.jpg"
            cv2.imwrite(output_path, result['annotated_image'])
            print(f"  ğŸ’¾ æ ‡æ³¨å›¾ç‰‡å·²ä¿å­˜: {output_path}")
        
        # æå–IMä¿¡æ¯
        im_info = detector.extract_im_info(str(img_path))
        
        print(f"  ğŸ“‹ IMä¿¡æ¯æå–:")
        print(f"    - æ¥æ”¶è€…: {'âœ… æ£€æµ‹åˆ°' if im_info['receiver'] else 'âŒ æœªæ£€æµ‹åˆ°'}")
        print(f"    - è¾“å…¥æ¡†: {'âœ… æ£€æµ‹åˆ°' if im_info['input_text'] else 'âŒ æœªæ£€æµ‹åˆ°'}")
        print(f"    - è”ç³»äºº: {len(im_info['contacts'])} ä¸ª")
        print(f"    - æ¶ˆæ¯: {len(im_info['messages'])} æ¡")
    
    return True


def demo_end2end():
    """æ¼”ç¤ºç«¯åˆ°ç«¯æµç¨‹"""
    print("\nğŸš€ æ¼”ç¤ºï¼šç«¯åˆ°ç«¯æµç¨‹")
    print("=" * 40)
    
    # æ£€æŸ¥å›¾ç‰‡
    raw_images = list(Path("./data/raw_images").glob("*.jpg"))
    if len(raw_images) < 5:
        print("âŒ éœ€è¦è‡³å°‘5å¼ IMæˆªå›¾è¿›è¡Œç«¯åˆ°ç«¯æ¼”ç¤º")
        print("è¯·å°†æ›´å¤šæˆªå›¾æ”¾å…¥ ./data/raw_images/ æ–‡ä»¶å¤¹")
        return False
    
    pipeline = End2EndIMDetector()
    
    try:
        print("ğŸ¬ å¼€å§‹ç«¯åˆ°ç«¯æ¼”ç¤ºï¼ˆä½¿ç”¨å‰5å¼ å›¾ç‰‡ï¼‰...")
        
        # å¿«é€Ÿæ„å»º
        model_path = pipeline.quick_build(
            "./data/raw_images", 
            num_images=5  # åªç”¨5å¼ å›¾ç‰‡æ¼”ç¤º
        )
        
        print(f"âœ… ç«¯åˆ°ç«¯æ„å»ºå®Œæˆï¼")
        print(f"ğŸ“„ æ¨¡å‹è·¯å¾„: {model_path}")
        
        # æµ‹è¯•æ£€æµ‹
        test_images = raw_images[:2]
        print(f"\nğŸ”¬ æµ‹è¯•æ–°è®­ç»ƒçš„æ¨¡å‹...")
        
        for img_path in test_images:
            result = pipeline.predict(str(img_path))
            im_info = pipeline.extract_im_info(str(img_path))
            
            print(f"ğŸ“¸ {img_path.name}:")
            print(f"  æ¥æ”¶è€…: {'âœ…' if im_info['receiver'] else 'âŒ'}")
            print(f"  è¾“å…¥æ¡†: {'âœ…' if im_info['input_text'] else 'âŒ'}")
        
        # æ€§èƒ½æµ‹è¯•
        print(f"\nâš¡ æ€§èƒ½æµ‹è¯•...")
        metrics = pipeline.benchmark("./data/raw_images", num_images=3)
        print(f"  å¹³å‡FPS: {metrics['avg_fps']:.2f}")
        print(f"  å¹³å‡å»¶è¿Ÿ: {metrics['avg_inference_time_ms']:.2f} ms")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç«¯åˆ°ç«¯æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ­ IMæ£€æµ‹å™¨å®Œæ•´æ¼”ç¤º")
    print("=" * 50)
    
    # 1. ç¯å¢ƒæ£€æŸ¥
    if not check_requirements():
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–åŒ…")
        return
    
    # 2. åˆ›å»ºç¤ºä¾‹æ•°æ®ç»“æ„
    create_sample_data()
    
    print("\nğŸ¯ æ¼”ç¤ºèœå•ï¼š")
    print("1. ğŸ·ï¸  GPT-4Vè‡ªåŠ¨æ ‡æ³¨æ¼”ç¤º")
    print("2. ğŸš‚ YOLOè®­ç»ƒæ¼”ç¤º")
    print("3. ğŸ” æ£€æµ‹åŠŸèƒ½æ¼”ç¤º")
    print("4. ğŸš€ ç«¯åˆ°ç«¯æµç¨‹æ¼”ç¤º")
    print("5. ğŸ¬ å®Œæ•´æ¼”ç¤ºï¼ˆæ¨èï¼‰")
    
    while True:
        choice = input("\nè¯·é€‰æ‹©æ¼”ç¤ºé¡¹ç›® (1-5, qé€€å‡º): ").strip().lower()
        
        if choice == 'q':
            print("ğŸ‘‹ æ¼”ç¤ºç»“æŸ")
            break
        elif choice == '1':
            demo_auto_labeling()
        elif choice == '2':
            demo_training()
        elif choice == '3':
            demo_detection()
        elif choice == '4':
            demo_end2end()
        elif choice == '5':
            print("\nğŸ¬ å¼€å§‹å®Œæ•´æ¼”ç¤ºæµç¨‹...")
            success = True
            
            # æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æ¼”ç¤º
            if success:
                success = demo_auto_labeling()
            if success:
                success = demo_training()
            if success:
                success = demo_detection()
            
            if success:
                print("\nğŸ‰ å®Œæ•´æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
                print("\nğŸ“‹ æ¼”ç¤ºæ€»ç»“ï¼š")
                print("  âœ… GPT-4Vè‡ªåŠ¨æ ‡æ³¨ - å®Œæˆ")
                print("  âœ… YOLOæ¨¡å‹è®­ç»ƒ - å®Œæˆ")  
                print("  âœ… IMå…ƒç´ æ£€æµ‹ - å®Œæˆ")
                print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
                print("  - æ ‡æ³¨æ•°æ®: ./data/labeled_data/demo/")
                print("  - è®­ç»ƒæ¨¡å‹: ./models/demo_model.pt")
                print("  - æ£€æµ‹ç»“æœ: ./demo_results/")
            else:
                print("\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-5æˆ–q")


if __name__ == "__main__":
    main()
