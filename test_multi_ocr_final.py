# -*- coding: utf-8 -*-
"""
çœŸå®OCRæ€§èƒ½æµ‹è¯• - å®Œæ•´å›¾ç‰‡ vs å±€éƒ¨åŒºåŸŸ
æ”¯æŒè‡ªå®šä¹‰åæ ‡åŒºåŸŸæµ‹è¯•
"""

import cv2
import numpy as np
import time
from ultrafast_ocr.intelligent_multiline_ocr import IntelligentMultilineOCR
from ultrafast_ocr import UltraFastOCR


class RealOCRWrapper:
    """çœŸå®OCRå¼•æ“åŒ…è£…å™¨ï¼Œè®°å½•è¯¦ç»†è°ƒç”¨ä¿¡æ¯"""
    def __init__(self, use_gpu=True):
        self.real_ocr = UltraFastOCR(use_gpu=use_gpu)
        self.call_count = 0
        self.call_details = []
        self.total_time = 0
    
    def recognize_single_line(self, image):
        """çœŸå®å•è¡Œè¯†åˆ«"""
        start_time = time.time()
        
        self.call_count += 1
        h, w = image.shape[:2]
        
        # è°ƒç”¨çœŸå®çš„OCR
        try:
            result = self.real_ocr.recognize_single_line(image)
            if not result or not result.strip():
                result = ""  # ç©ºç™½ç»“æœ
        except Exception as e:
            result = f"[Error: {str(e)[:30]}]"
            print(f"OCRé”™è¯¯ #{self.call_count}: {e}")
        
        actual_time = time.time() - start_time
        self.total_time += actual_time
        
        # è®°å½•è°ƒç”¨è¯¦æƒ…
        self.call_details.append({
            'call_id': self.call_count,
            'image_size': (w, h),
            'pixels': w * h,
            'time_ms': actual_time * 1000,
            'result_length': len(result) if result else 0,
            'is_empty': not bool(result.strip()) if result else True
        })
        
        return result
    
    def reset(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.call_count = 0
        self.call_details = []
        self.total_time = 0
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.call_details:
            return {}
        
        times = [call['time_ms'] for call in self.call_details]
        pixels = [call['pixels'] for call in self.call_details]
        empty_count = sum(1 for call in self.call_details if call['is_empty'])
        
        return {
            'total_calls': self.call_count,
            'total_time_ms': self.total_time * 1000,
            'avg_time_ms': np.mean(times),
            'min_time_ms': min(times),
            'max_time_ms': max(times),
            'avg_pixels': np.mean(pixels),
            'total_pixels': sum(pixels),
            'empty_results': empty_count,
            'success_rate': (self.call_count - empty_count) / self.call_count if self.call_count > 0 else 0
        }


def create_test_document():
    """åˆ›å»ºæµ‹è¯•æ–‡æ¡£"""
    # åˆ›å»ºä¸€ä¸ªä¸­ç­‰å¤§å°çš„æµ‹è¯•æ–‡æ¡£
    img = np.ones((600, 900, 3), dtype=np.uint8) * 255
    
    # æ ‡é¢˜
    cv2.putText(img, "OCR Performance Test Document", (50, 50), 
                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 2)
    
    # ç¬¬ä¸€æ®µè½
    paragraph1 = [
        "This is the first paragraph for testing.",
        "It contains multiple lines of text content.",
        "Each line will be processed by the OCR system."
    ]
    
    y_pos = 120
    for line in paragraph1:
        cv2.putText(img, line, (50, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
        y_pos += 40
    
    # è¡¨æ ¼
    cv2.putText(img, "Data Table:", (50, y_pos + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
    y_pos += 60
    
    table_rows = [
        ["ID", "Name", "Score", "Grade"],
        ["001", "Alice", "95", "A"],
        ["002", "Bob", "87", "B"],
        ["003", "Carol", "92", "A"]
    ]
    
    for row in table_rows:
        x_pos = 70
        for cell in row:
            cv2.putText(img, cell, (x_pos, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            x_pos += 120
        y_pos += 30
    
    # ç¬¬äºŒæ®µè½
    paragraph2 = [
        "Second paragraph with additional content.",
        "Testing the OCR performance on mixed layouts.",
        "This includes both regular text and tabular data."
    ]
    
    y_pos += 30
    for line in paragraph2:
        cv2.putText(img, line, (50, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
        y_pos += 40
    
    return img


def extract_region(image, x1, y1, x2, y2, region_name=None):
    """æå–å›¾åƒçš„æŒ‡å®šåŒºåŸŸ"""
    h, w = image.shape[:2]
    
    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(w, x2), min(h, y2)
    
    if x1 >= x2 or y1 >= y2:
        raise ValueError(f"æ— æ•ˆçš„åŒºåŸŸåæ ‡: ({x1},{y1}) -> ({x2},{y2})")
    
    region = image[y1:y2, x1:x2]
    
    if region_name:
        print(f"æå–åŒºåŸŸ '{region_name}': ({x1},{y1}) -> ({x2},{y2}), å°ºå¯¸: {x2-x1}x{y2-y1}")
    
    return region


def run_ocr_test(image, region_name, ocr_instance):
    """æ‰§è¡ŒOCRæµ‹è¯•"""
    real_ocr = ocr_instance.ocr
    real_ocr.reset()
    
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•åŒºåŸŸ: {region_name}")
    print(f"{'='*60}")
    
    # è·å–å›¾åƒä¿¡æ¯
    h, w = image.shape[:2]
    print(f"å›¾åƒå°ºå¯¸: {w} x {h} ({w*h:,} åƒç´ )")
    
    # åˆ†æ­¥è®¡æ—¶æ‰§è¡Œ
    total_start = time.time()
    
    # æ­¥éª¤1: ç»“æ„åˆ†æ
    step_start = time.time()
    structure_info = ocr_instance.analyze_text_structure(image)
    analysis_time = time.time() - step_start
    
    # æ­¥éª¤2: è¡Œæ£€æµ‹
    step_start = time.time()
    lines = ocr_instance.detect_text_lines(image, structure_info)
    detection_time = time.time() - step_start
    
    # æ­¥éª¤3: æ‹¼æ¥ä¼˜åŒ–
    step_start = time.time()
    concat_groups = ocr_instance.optimize_concatenation(lines)
    concat_time = time.time() - step_start
    
    # æ­¥éª¤4: OCRè¯†åˆ«
    step_start = time.time()
    results = ocr_instance.recognize_multiline(image)
    recognition_time = time.time() - step_start
    
    total_time = time.time() - total_start
    
    # è·å–OCRç»Ÿè®¡
    ocr_stats = real_ocr.get_stats()
    
    # è¾“å‡ºè¯†åˆ«ç»“æœ
    print(f"\nğŸ“ è¯†åˆ«ç»“æœ ({len(results)} è¡Œ):")
    for i, text in enumerate(results[:8], 1):  # æœ€å¤šæ˜¾ç¤º8è¡Œ
        display_text = text[:50] + "..." if len(text) > 50 else text
        print(f"  {i:2d}. {display_text}")
    if len(results) > 8:
        print(f"  ... (æ€»å…± {len(results)} è¡Œ)")
    
    # è¾“å‡ºæ€§èƒ½ç»Ÿè®¡
    print(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
    print(f"  æ€»å¤„ç†æ—¶é—´: {total_time*1000:6.1f}ms")
    print(f"  - ç»“æ„åˆ†æ: {analysis_time*1000:6.1f}ms ({analysis_time/total_time*100:4.1f}%)")
    print(f"  - è¡Œæ£€æµ‹:   {detection_time*1000:6.1f}ms ({detection_time/total_time*100:4.1f}%)")
    print(f"  - æ‹¼æ¥ä¼˜åŒ–: {concat_time*1000:6.1f}ms ({concat_time/total_time*100:4.1f}%)")
    print(f"  - OCRè¯†åˆ«:  {recognition_time*1000:6.1f}ms ({recognition_time/total_time*100:4.1f}%)")
    
    print(f"\nğŸ”¢ OCRè°ƒç”¨ç»Ÿè®¡:")
    print(f"  æ£€æµ‹è¡Œæ•°:     {len(lines):3d}")
    print(f"  æ‹¼æ¥ç»„æ•°:     {len(concat_groups):3d}")
    print(f"  OCRè°ƒç”¨æ¬¡æ•°:  {ocr_stats['total_calls']:3d}")
    print(f"  æˆåŠŸè¯†åˆ«:     {ocr_stats['total_calls'] - ocr_stats['empty_results']:3d}")
    print(f"  ç©ºç™½ç»“æœ:     {ocr_stats['empty_results']:3d}")
    print(f"  æˆåŠŸç‡:       {ocr_stats['success_rate']*100:5.1f}%")
    print(f"  æ•ˆç‡æå‡:     {len(lines)/ocr_stats['total_calls']:5.1f}x")
    print(f"  å¹³å‡OCRæ—¶é—´:  {ocr_stats['avg_time_ms']:6.1f}ms")
    
    # æ˜¾ç¤ºæ‹¼æ¥è¯¦æƒ…
    print(f"\nğŸ”— æ‹¼æ¥åˆ†ç»„è¯¦æƒ…:")
    for i, (_, indices) in enumerate(concat_groups[:5], 1):  # æœ€å¤šæ˜¾ç¤º5ç»„
        print(f"  ç»„{i}: {len(indices)}è¡Œ (è¡Œå·: {[idx+1 for idx in indices]})")
    if len(concat_groups) > 5:
        print(f"  ... (æ€»å…± {len(concat_groups)} ç»„)")
    
    return {
        'region_name': region_name,
        'image_size': (w, h),
        'total_pixels': w * h,
        'detected_lines': len(lines),
        'concat_groups': len(concat_groups),
        'recognized_lines': len(results),
        'total_time_ms': total_time * 1000,
        'analysis_time_ms': analysis_time * 1000,
        'detection_time_ms': detection_time * 1000,
        'concat_time_ms': concat_time * 1000,
        'recognition_time_ms': recognition_time * 1000,
        'ocr_calls': ocr_stats['total_calls'],
        'ocr_time_ms': ocr_stats['total_time_ms'],
        'success_rate': ocr_stats['success_rate'],
        'efficiency': len(lines)/ocr_stats['total_calls'] if ocr_stats['total_calls'] > 0 else 0,
        'results': results
    }


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("çœŸå®OCRæ€§èƒ½æµ‹è¯•")
    print("="*80)
    
    # åˆå§‹åŒ–OCRå¼•æ“
    print("ğŸš€ åˆå§‹åŒ–OCRå¼•æ“...")
    try:
        real_ocr = RealOCRWrapper(use_gpu=True)  # å…ˆå°è¯•GPU
        print("âœ… OCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ (GPU)")
    except Exception as e:
        print(f"âš ï¸  GPUåˆå§‹åŒ–å¤±è´¥ï¼Œåˆ‡æ¢åˆ°CPU: {e}")
        try:
            real_ocr = RealOCRWrapper(use_gpu=False)
            print("âœ… OCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ (CPU)")
        except Exception as e:
            print(f"âŒ OCRå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            return None
    
    # åˆ›å»ºæ™ºèƒ½å¤šè¡ŒOCRå®ä¾‹
    ocr_instance = IntelligentMultilineOCR(
        ocr_engine=real_ocr,
        dynamic_width=True,
        width_strategy='adaptive'
    )
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    print("ğŸ“„ åˆ›å»ºæµ‹è¯•æ–‡æ¡£...")
    full_image = create_test_document()
    
    # ä¿å­˜æµ‹è¯•å›¾åƒï¼ˆå¯é€‰ï¼‰
    cv2.imwrite("test_document.jpg", full_image)
    print("ğŸ’¾ æµ‹è¯•å›¾åƒå·²ä¿å­˜ä¸º: test_document.jpg")
    
    # æµ‹è¯•ç»“æœå­˜å‚¨
    all_results = []
    
    # æµ‹è¯•1: å®Œæ•´å›¾åƒ
    result = run_ocr_test(full_image, "å®Œæ•´æ–‡æ¡£", ocr_instance)
    all_results.append(result)
    
    # æµ‹è¯•2: é¢„å®šä¹‰åŒºåŸŸ
    predefined_regions = [
        (50, 0, 900, 100, "æ ‡é¢˜åŒºåŸŸ"),          # æ ‡é¢˜éƒ¨åˆ†
        (50, 100, 900, 280, "ç¬¬ä¸€æ®µè½"),        # ç¬¬ä¸€æ®µè½
        (50, 280, 900, 420, "è¡¨æ ¼åŒºåŸŸ"),        # è¡¨æ ¼éƒ¨åˆ†
        (50, 420, 900, 550, "ç¬¬äºŒæ®µè½"),        # ç¬¬äºŒæ®µè½
        (0, 0, 450, 600, "å·¦åŠéƒ¨åˆ†"),           # å·¦åŠè¾¹
        (450, 0, 900, 600, "å³åŠéƒ¨åˆ†"),         # å³åŠè¾¹
    ]
    
    print(f"\nğŸ¯ æµ‹è¯•é¢„å®šä¹‰åŒºåŸŸ ({len(predefined_regions)} ä¸ªåŒºåŸŸ):")
    for x1, y1, x2, y2, name in predefined_regions:
        try:
            region_img = extract_region(full_image, x1, y1, x2, y2, name)
            result = run_ocr_test(region_img, name, ocr_instance)
            all_results.append(result)
        except Exception as e:
            print(f"âŒ åŒºåŸŸ '{name}' æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•3: è‡ªå®šä¹‰åŒºåŸŸï¼ˆç”¨æˆ·å¯ä»¥ä¿®æ”¹è¿™äº›åæ ‡ï¼‰
    custom_regions = [
        (100, 150, 800, 250, "è‡ªå®šä¹‰åŒºåŸŸ1"),    # ç”¨æˆ·å¯è‡ªå®šä¹‰
        (200, 300, 700, 400, "è‡ªå®šä¹‰åŒºåŸŸ2"),    # ç”¨æˆ·å¯è‡ªå®šä¹‰
    ]
    
    print(f"\nâœï¸  æµ‹è¯•è‡ªå®šä¹‰åŒºåŸŸ ({len(custom_regions)} ä¸ªåŒºåŸŸ):")
    for x1, y1, x2, y2, name in custom_regions:
        try:
            region_img = extract_region(full_image, x1, y1, x2, y2, name)
            result = run_ocr_test(region_img, name, ocr_instance)
            all_results.append(result)
        except Exception as e:
            print(f"âŒ åŒºåŸŸ '{name}' æµ‹è¯•å¤±è´¥: {e}")
    
    # æ€§èƒ½å¯¹æ¯”åˆ†æ
    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("="*80)
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    print(f"{'åŒºåŸŸåç§°':15} {'å°ºå¯¸':12} {'è¯†åˆ«':4} {'OCR':4} {'æ—¶é—´':7} {'æ•ˆç‡':6} {'æˆåŠŸç‡':7}")
    print("-" * 75)
    
    total_region_time = 0
    total_region_calls = 0
    total_region_lines = 0
    
    for i, result in enumerate(all_results):
        name = result['region_name'][:14]
        size = f"{result['image_size'][0]}x{result['image_size'][1]}"
        lines = result['recognized_lines']
        calls = result['ocr_calls']
        time_ms = result['total_time_ms']
        eff = result['efficiency']
        success = result['success_rate']
        
        print(f"{name:15} {size:12} {lines:4d} {calls:4d} {time_ms:6.0f}ms {eff:6.1f}x {success*100:6.1f}%")
        
        if i > 0:  # è·³è¿‡å®Œæ•´æ–‡æ¡£ï¼Œåªç»Ÿè®¡åŒºåŸŸ
            total_region_time += time_ms
            total_region_calls += calls
            total_region_lines += lines
    
    # å®Œæ•´æ–‡æ¡£ vs åŒºåŸŸæ€»è®¡å¯¹æ¯”
    full_doc = all_results[0]
    print(f"\nğŸ” æ•´ä½“å¯¹æ¯”:")
    print(f"å®Œæ•´æ–‡æ¡£:   æ—¶é—´={full_doc['total_time_ms']:6.0f}ms, OCRè°ƒç”¨={full_doc['ocr_calls']:3d}, è¯†åˆ«={full_doc['recognized_lines']:3d}è¡Œ")
    print(f"åŒºåŸŸæ€»è®¡:   æ—¶é—´={total_region_time:6.0f}ms, OCRè°ƒç”¨={total_region_calls:3d}, è¯†åˆ«={total_region_lines:3d}è¡Œ")
    
    time_diff = total_region_time - full_doc['total_time_ms']
    calls_diff = total_region_calls - full_doc['ocr_calls']
    
    print(f"å·®å¼‚:       æ—¶é—´={time_diff:+6.0f}ms ({time_diff/full_doc['total_time_ms']*100:+5.1f}%), OCR={calls_diff:+3d}æ¬¡")
    
    if time_diff < 0:
        print("ğŸ† å®Œæ•´æ–‡æ¡£å¤„ç†æ›´é«˜æ•ˆï¼")
    else:
        print("ğŸ“‹ åˆ†åŒºåŸŸå¤„ç†åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æœ‰ä¼˜åŠ¿")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆï¼å…±æµ‹è¯•äº† {len(all_results)} ä¸ªåŒºåŸŸ")
    return all_results


def test_custom_region():
    """è‡ªå®šä¹‰åŒºåŸŸæµ‹è¯•å‡½æ•° - ç”¨æˆ·å¯ä»¥è°ƒç”¨æ­¤å‡½æ•°æµ‹è¯•ç‰¹å®šåæ ‡"""
    print("ğŸ¯ è‡ªå®šä¹‰åŒºåŸŸæµ‹è¯•")
    print("="*50)
    
    # ç”¨æˆ·å¯ä»¥ä¿®æ”¹è¿™äº›å‚æ•°
    image_path = "test_document.jpg"  # å›¾åƒè·¯å¾„
    x1, y1, x2, y2 = 100, 200, 800, 400  # è‡ªå®šä¹‰åæ ‡
    region_name = "ç”¨æˆ·è‡ªå®šä¹‰åŒºåŸŸ"
    
    try:
        # åŠ è½½å›¾åƒ
        if image_path == "test_document.jpg":
            # å¦‚æœæ˜¯æµ‹è¯•æ–‡æ¡£ï¼Œé‡æ–°ç”Ÿæˆ
            image = create_test_document()
        else:
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
        
        # æå–åŒºåŸŸ
        region = extract_region(image, x1, y1, x2, y2, region_name)
        
        # åˆå§‹åŒ–OCR
        real_ocr = RealOCRWrapper(use_gpu=False)
        ocr_instance = IntelligentMultilineOCR(
            ocr_engine=real_ocr,
            dynamic_width=True,
            width_strategy='adaptive'
        )
        
        # æ‰§è¡Œæµ‹è¯•
        result = run_ocr_test(region, region_name, ocr_instance)
        
        print(f"âœ… è‡ªå®šä¹‰åŒºåŸŸæµ‹è¯•å®Œæˆ")
        return result
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰åŒºåŸŸæµ‹è¯•å¤±è´¥: {e}")
        return None


if __name__ == "__main__":
    try:
        # è¿è¡Œä¸»æµ‹è¯•
        results = main()
        
        print(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("1. ä¿®æ”¹ test_custom_region() å‡½æ•°ä¸­çš„åæ ‡æ¥æµ‹è¯•ç‰¹å®šåŒºåŸŸ")
        print("2. ä¿®æ”¹ custom_regions åˆ—è¡¨æ¥æ·»åŠ æ›´å¤šè‡ªå®šä¹‰åŒºåŸŸ") 
        print("3. æŸ¥çœ‹ç”Ÿæˆçš„ test_document.jpg æ¥äº†è§£æµ‹è¯•å›¾åƒ")
        print("4. æ ¹æ®æµ‹è¯•ç»“æœè°ƒæ•´ width_strategy å‚æ•°ä¼˜åŒ–æ€§èƒ½")
        
        # å¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥è¿è¡Œè‡ªå®šä¹‰åŒºåŸŸæµ‹è¯•
        # test_custom_region()
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
