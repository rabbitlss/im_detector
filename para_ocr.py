# -*- coding: utf-8 -*-
"""
å¹¶è¡ŒåŒºåŸŸOCRè¯†åˆ«è„šæœ¬
æ”¯æŒå¤šGPU/å¤šè¿›ç¨‹å¹¶å‘æ‰§è¡ŒOCRè¯†åˆ«
"""

import cv2
import numpy as np
import time
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import multiprocessing as mp
from queue import Queue
import threading

@dataclass
class Region:
    """åŒºåŸŸå®šä¹‰"""
    x1: int
    y1: int
    x2: int
    y2: int
    label: str = ""
    index: int = 0

@dataclass
class RegionOCRResult:
    """åŒºåŸŸOCRç»“æœ"""
    region: Region
    text: str
    time_ms: float
    worker_id: str  # æ ‡è¯†å“ªä¸ªworkerå¤„ç†çš„

class OCRWorker:
    """OCRå·¥ä½œå™¨ï¼ˆæ¯ä¸ªGPUä¸€ä¸ªå®ä¾‹ï¼‰"""
    
    def __init__(self, worker_id: int, device: str = 'cpu'):
        """
        åˆå§‹åŒ–OCRå·¥ä½œå™¨
        
        Args:
            worker_id: å·¥ä½œå™¨ID
            device: è®¾å¤‡ç±»å‹ ('cpu', 'cuda:0', 'cuda:1', etc.)
        """
        self.worker_id = worker_id
        self.device = device
        
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…åœ¨ä¸»è¿›ç¨‹ä¸­åˆå§‹åŒ–
        from ultrafast_ocr.core import UltraFastOCR
        
        # æ ¹æ®è®¾å¤‡åˆå§‹åŒ–OCR
        if 'cuda' in device:
            import os
            # è®¾ç½®CUDAè®¾å¤‡
            gpu_id = int(device.split(':')[1]) if ':' in device else 0
            os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
            
        self.ocr = UltraFastOCR()
        print(f"âœ… Worker {worker_id} åˆå§‹åŒ–å®Œæˆ (è®¾å¤‡: {device})")
    
    def process_region(self, image: np.ndarray, region: Region) -> RegionOCRResult:
        """å¤„ç†å•ä¸ªåŒºåŸŸ"""
        x1, y1, x2, y2 = region.x1, region.y1, region.x2, region.y2
        roi = image[y1:y2, x1:x2]
        
        if roi.size == 0:
            return RegionOCRResult(
                region=region,
                text="",
                time_ms=0,
                worker_id=f"worker_{self.worker_id}"
            )
        
        start = time.time()
        text = self.ocr.recognize_single_line(roi)
        time_ms = (time.time() - start) * 1000
        
        return RegionOCRResult(
            region=region,
            text=text,
            time_ms=time_ms,
            worker_id=f"worker_{self.worker_id}"
        )

def process_region_batch(args):
    """å¤„ç†ä¸€æ‰¹åŒºåŸŸï¼ˆç”¨äºè¿›ç¨‹æ± ï¼‰"""
    worker_id, device, image, regions = args
    worker = OCRWorker(worker_id, device)
    results = []
    
    for region in regions:
        result = worker.process_region(image, region)
        results.append(result)
        
    return results

class ParallelRegionOCR:
    """å¹¶è¡ŒåŒºåŸŸOCRå¤„ç†å™¨"""
    
    def __init__(self, num_workers: int = None, use_gpu: bool = True, gpu_ids: List[int] = None):
        """
        åˆå§‹åŒ–å¹¶è¡ŒOCRå¤„ç†å™¨
        
        Args:
            num_workers: å·¥ä½œå™¨æ•°é‡ï¼ˆNoneåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            gpu_ids: æŒ‡å®šGPU IDåˆ—è¡¨ï¼ˆå¦‚ [0, 1, 2]ï¼‰
        """
        self.use_gpu = use_gpu
        
        # ç¡®å®šå·¥ä½œå™¨æ•°é‡å’Œè®¾å¤‡
        if use_gpu and gpu_ids:
            self.devices = [f"cuda:{gpu_id}" for gpu_id in gpu_ids]
            self.num_workers = len(gpu_ids)
        elif use_gpu:
            # è‡ªåŠ¨æ£€æµ‹GPUæ•°é‡ï¼ˆä½¿ç”¨æœ€ç®€å•çš„æ–¹æ³•ï¼‰
            gpu_count = self._detect_gpu_count()
            if gpu_count > 0:
                self.devices = [f"cuda:{i}" for i in range(gpu_count)]
                self.num_workers = gpu_count
            else:
                print("âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPU")
                self.devices = ["cpu"]
                self.num_workers = num_workers or mp.cpu_count()
        else:
            self.devices = ["cpu"] * (num_workers or mp.cpu_count())
            self.num_workers = len(self.devices)
        
        print(f"ğŸš€ å¹¶è¡ŒOCRå¤„ç†å™¨åˆå§‹åŒ–:")
        print(f"   - å·¥ä½œå™¨æ•°é‡: {self.num_workers}")
        print(f"   - è®¾å¤‡åˆ—è¡¨: {self.devices}")
    
    def _detect_gpu_count(self) -> int:
        """
        ç®€å•çš„GPUæ£€æµ‹æ–¹æ³•
        ä¼˜å…ˆçº§: PyTorch > nvidia-smi > 0
        """
        # æ–¹æ³•1: å°è¯•PyTorchï¼ˆæœ€å¸¸ç”¨ï¼‰
        try:
            import torch
            if torch.cuda.is_available():
                return torch.cuda.device_count()
        except ImportError:
            pass
        
        # æ–¹æ³•2: å°è¯•nvidia-smiå‘½ä»¤
        try:
            import subprocess
            result = subprocess.run(
                ['nvidia-smi', '-L'],
                capture_output=True,
                text=True,
                check=True,
                timeout=5
            )
            # è®¡ç®—è¾“å‡ºè¡Œæ•°ï¼ˆæ¯è¡Œä¸€ä¸ªGPUï¼‰
            lines = result.stdout.strip().split('\n')
            return len([l for l in lines if l.strip()])
        except:
            pass
        
        # æ–¹æ³•3: æ£€æŸ¥CUDAç¯å¢ƒå˜é‡
        import os
        cuda_visible = os.environ.get('CUDA_VISIBLE_DEVICES', '')
        if cuda_visible and cuda_visible != '-1':
            # CUDA_VISIBLE_DEVICES="0,1,2" è¡¨ç¤º3ä¸ªGPU
            gpu_ids = [g.strip() for g in cuda_visible.split(',') if g.strip()]
            if gpu_ids:
                return len(gpu_ids)
        
        # é»˜è®¤è¿”å›0ï¼ˆæ²¡æœ‰GPUï¼‰
        return 0
    
    def recognize_regions_parallel_thread(self, 
                                         image: np.ndarray,
                                         regions: List[Tuple[int, int, int, int]],
                                         labels: List[str] = None) -> List[str]:
        """
        ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè¯†åˆ«ï¼ˆå…±äº«å†…å­˜ï¼Œé€‚åˆI/Oå¯†é›†å‹ï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            regions: åŒºåŸŸåæ ‡åˆ—è¡¨
            labels: å¯é€‰çš„åŒºåŸŸæ ‡ç­¾
            
        Returns:
            è¯†åˆ«æ–‡æœ¬åˆ—è¡¨
        """
        print(f"ğŸ” ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè¯†åˆ« {len(regions)} ä¸ªåŒºåŸŸ...")
        start_time = time.time()
        
        # åˆ›å»ºRegionå¯¹è±¡
        region_objs = []
        for i, (x1, y1, x2, y2) in enumerate(regions):
            label = labels[i] if labels and i < len(labels) else f"region_{i}"
            region_objs.append(Region(x1, y1, x2, y2, label, i))
        
        # åˆ›å»ºå·¥ä½œå™¨
        workers = [OCRWorker(i, self.devices[i % len(self.devices)]) 
                  for i in range(self.num_workers)]
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        results = [None] * len(regions)
        
        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_region = {}
            for i, region in enumerate(region_objs):
                worker = workers[i % self.num_workers]
                future = executor.submit(worker.process_region, image, region)
                future_to_region[future] = i
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_region):
                idx = future_to_region[future]
                result = future.result()
                results[idx] = result.text
                
                # æ˜¾ç¤ºè¿›åº¦
                print(f"   [{result.worker_id}] {result.region.label}: {result.text[:30]}..." 
                      if len(result.text) > 30 else 
                      f"   [{result.worker_id}] {result.region.label}: {result.text}")
        
        total_time = (time.time() - start_time) * 1000
        print(f"\nâœ… å¹¶è¡Œè¯†åˆ«å®Œæˆ:")
        print(f"   - æ€»è€—æ—¶: {total_time:.1f}ms")
        print(f"   - å¹³å‡æ¯åŒºåŸŸ: {total_time/len(regions):.1f}ms")
        print(f"   - åŠ é€Ÿæ¯”: {len(regions)/(total_time/1000)/self.num_workers:.2f}x")
        
        return results
    
    def recognize_regions_parallel_process(self,
                                          image: np.ndarray,
                                          regions: List[Tuple[int, int, int, int]],
                                          labels: List[str] = None) -> List[str]:
        """
        ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œè¯†åˆ«ï¼ˆç‹¬ç«‹å†…å­˜ï¼Œé€‚åˆCPUå¯†é›†å‹ï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            regions: åŒºåŸŸåæ ‡åˆ—è¡¨
            labels: å¯é€‰çš„åŒºåŸŸæ ‡ç­¾
            
        Returns:
            è¯†åˆ«æ–‡æœ¬åˆ—è¡¨
        """
        print(f"ğŸ” ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œè¯†åˆ« {len(regions)} ä¸ªåŒºåŸŸ...")
        start_time = time.time()
        
        # åˆ›å»ºRegionå¯¹è±¡
        region_objs = []
        for i, (x1, y1, x2, y2) in enumerate(regions):
            label = labels[i] if labels and i < len(labels) else f"region_{i}"
            region_objs.append(Region(x1, y1, x2, y2, label, i))
        
        # å°†åŒºåŸŸåˆ†é…ç»™ä¸åŒçš„å·¥ä½œå™¨
        region_batches = [[] for _ in range(self.num_workers)]
        for i, region in enumerate(region_objs):
            region_batches[i % self.num_workers].append(region)
        
        # å‡†å¤‡è¿›ç¨‹æ± å‚æ•°
        process_args = []
        for i in range(self.num_workers):
            if region_batches[i]:  # åªå¤„ç†éç©ºæ‰¹æ¬¡
                device = self.devices[i % len(self.devices)]
                process_args.append((i, device, image, region_batches[i]))
        
        # ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†
        results_dict = {}
        
        with ProcessPoolExecutor(max_workers=len(process_args)) as executor:
            futures = [executor.submit(process_region_batch, args) for args in process_args]
            
            for future in as_completed(futures):
                batch_results = future.result()
                for result in batch_results:
                    results_dict[result.region.index] = result.text
                    print(f"   [{result.worker_id}] {result.region.label}: {result.text[:30]}..."
                          if len(result.text) > 30 else
                          f"   [{result.worker_id}] {result.region.label}: {result.text}")
        
        # æŒ‰åŸå§‹é¡ºåºæ’åˆ—ç»“æœ
        results = [results_dict.get(i, "") for i in range(len(regions))]
        
        total_time = (time.time() - start_time) * 1000
        print(f"\nâœ… å¹¶è¡Œè¯†åˆ«å®Œæˆ:")
        print(f"   - æ€»è€—æ—¶: {total_time:.1f}ms")
        print(f"   - å¹³å‡æ¯åŒºåŸŸ: {total_time/len(regions):.1f}ms")
        
        return results
    
    def recognize_regions_gpu_batch(self,
                                   image: np.ndarray,
                                   regions: List[Tuple[int, int, int, int]],
                                   labels: List[str] = None,
                                   batch_size: int = 8) -> List[str]:
        """
        çœŸæ­£çš„å¹¶è¡ŒGPUæ‰¹å¤„ç†è¯†åˆ«
        
        Args:
            image: è¾“å…¥å›¾åƒ
            regions: åŒºåŸŸåæ ‡åˆ—è¡¨
            labels: å¯é€‰çš„åŒºåŸŸæ ‡ç­¾
            batch_size: æ¯ä¸ªGPUçš„æ‰¹å¤„ç†å¤§å°
            
        Returns:
            è¯†åˆ«æ–‡æœ¬åˆ—è¡¨
        """
        if not self.use_gpu:
            print("âš ï¸ GPUæ‰¹å¤„ç†éœ€è¦GPUæ”¯æŒï¼Œåˆ‡æ¢åˆ°çº¿ç¨‹æ± æ¨¡å¼")
            return self.recognize_regions_parallel_thread(image, regions, labels)
        
        print(f"ğŸ” ä½¿ç”¨å¹¶è¡ŒGPUæ‰¹å¤„ç†è¯†åˆ« {len(regions)} ä¸ªåŒºåŸŸ...")
        print(f"   - GPUæ•°é‡: {len(self.devices)}")
        print(f"   - æ¯GPUæ‰¹å¤§å°: {batch_size}")
        
        start_time = time.time()
        
        # åˆ›å»ºGPUå·¥ä½œå™¨
        gpu_workers = []
        for i, device in enumerate(self.devices):
            try:
                worker = OCRWorker(i, device)
                gpu_workers.append(worker)
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åˆå§‹åŒ–GPU {device}: {e}")
        
        if not gpu_workers:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„GPUå·¥ä½œå™¨")
            return []
        
        # å‡†å¤‡Regionå¯¹è±¡
        region_objs = []
        for i, (x1, y1, x2, y2) in enumerate(regions):
            label = labels[i] if labels and i < len(labels) else f"region_{i}"
            region_objs.append(Region(x1, y1, x2, y2, label, i))
        
        # å°†åŒºåŸŸåˆ†é…ç»™ä¸åŒçš„GPUï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
        gpu_tasks = [[] for _ in gpu_workers]
        for i, region in enumerate(region_objs):
            gpu_idx = i % len(gpu_workers)
            gpu_tasks[gpu_idx].append(region)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼ˆæ¯ä¸ªGPUä¸€ä¸ªçº¿ç¨‹ï¼‰
        results_dict = {}
        gpu_time_stats = {}  # è®°å½•æ¯ä¸ªGPUçš„æ—¶é—´ç»Ÿè®¡
        
        with ThreadPoolExecutor(max_workers=len(gpu_workers)) as executor:
            # å®šä¹‰GPUå¤„ç†å‡½æ•°
            def process_gpu_batch(worker, task_regions):
                """å•ä¸ªGPUå¤„ç†å…¶åˆ†é…çš„æ‰€æœ‰åŒºåŸŸ"""
                gpu_start_time = time.time()
                local_results = []
                region_times = []  # è®°å½•æ¯ä¸ªåŒºåŸŸçš„å¤„ç†æ—¶é—´
                
                for region in task_regions:
                    region_start = time.time()
                    result = worker.process_region(image, region)
                    region_time = (time.time() - region_start) * 1000  # ms
                    
                    local_results.append((region.index, result))
                    region_times.append(region_time)
                    
                    print(f"   [GPU:{worker.worker_id}] {region.label}: {result.text[:30]}... ({region_time:.1f}ms)"
                          if len(result.text) > 30 else
                          f"   [GPU:{worker.worker_id}] {region.label}: {result.text} ({region_time:.1f}ms)")
                
                gpu_total_time = (time.time() - gpu_start_time) * 1000  # ms
                
                # è¿”å›ç»“æœå’Œæ—¶é—´ç»Ÿè®¡
                return {
                    'results': local_results,
                    'gpu_id': worker.worker_id,
                    'total_time': gpu_total_time,
                    'region_times': region_times,
                    'num_regions': len(task_regions)
                }
            
            # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± ï¼ˆæ¯ä¸ªGPUä¸€ä¸ªä»»åŠ¡ï¼‰
            future_to_gpu = {}
            for worker, tasks in zip(gpu_workers, gpu_tasks):
                if tasks:  # åªå¤„ç†æœ‰ä»»åŠ¡çš„GPU
                    future = executor.submit(process_gpu_batch, worker, tasks)
                    future_to_gpu[future] = worker.worker_id
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_gpu):
                gpu_result = future.result()
                gpu_id = gpu_result['gpu_id']
                
                # ä¿å­˜æ—¶é—´ç»Ÿè®¡
                gpu_time_stats[f'GPU_{gpu_id}'] = {
                    'total_time_ms': gpu_result['total_time'],
                    'num_regions': gpu_result['num_regions'],
                    'avg_time_ms': gpu_result['total_time'] / gpu_result['num_regions'] if gpu_result['num_regions'] > 0 else 0,
                    'min_time_ms': min(gpu_result['region_times']) if gpu_result['region_times'] else 0,
                    'max_time_ms': max(gpu_result['region_times']) if gpu_result['region_times'] else 0,
                    'region_times': gpu_result['region_times']
                }
                
                # ä¿å­˜è¯†åˆ«ç»“æœ
                for region_idx, result in gpu_result['results']:
                    results_dict[region_idx] = result.text
        
        # æŒ‰åŸå§‹é¡ºåºæ’åˆ—ç»“æœ
        results = [results_dict.get(i, "") for i in range(len(regions))]
        
        total_time = (time.time() - start_time) * 1000
        
        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        print(f"\nâœ… å¹¶è¡ŒGPUæ‰¹å¤„ç†å®Œæˆ:")
        print(f"   - æ€»è€—æ—¶: {total_time:.1f}ms")
        print(f"   - å¹³å‡æ¯åŒºåŸŸ: {total_time/len(regions):.1f}ms")
        print(f"   - ååé‡: {len(regions)/(total_time/1000):.1f} åŒºåŸŸ/ç§’")
        print(f"   - å¹¶è¡Œæ•ˆç‡: {len(regions)/(total_time/1000)/len(gpu_workers):.1f} åŒºåŸŸ/ç§’/GPU")
        
        # æ‰“å°æ¯ä¸ªGPUçš„è¯¦ç»†ç»Ÿè®¡
        print(f"\nğŸ“Š å„GPUæ—¶é—´ç»Ÿè®¡:")
        for gpu_name, stats in gpu_time_stats.items():
            print(f"   {gpu_name}:")
            print(f"      - å¤„ç†åŒºåŸŸæ•°: {stats['num_regions']}")
            print(f"      - æ€»è€—æ—¶: {stats['total_time_ms']:.1f}ms")
            print(f"      - å¹³å‡è€—æ—¶: {stats['avg_time_ms']:.1f}ms/åŒºåŸŸ")
            print(f"      - æœ€å¿«: {stats['min_time_ms']:.1f}ms")
            print(f"      - æœ€æ…¢: {stats['max_time_ms']:.1f}ms")
        
        # è®¡ç®—å¹¶è¡ŒåŠ é€Ÿæ¯”
        if gpu_time_stats:
            # ä¸²è¡Œæ—¶é—´ = æ‰€æœ‰GPUå¤„ç†æ—¶é—´ä¹‹å’Œ
            serial_time = sum(stats['total_time_ms'] for stats in gpu_time_stats.values())
            # å¹¶è¡Œæ—¶é—´ = æœ€æ…¢çš„GPUå®Œæˆæ—¶é—´
            parallel_time = max(stats['total_time_ms'] for stats in gpu_time_stats.values())
            speedup = serial_time / parallel_time if parallel_time > 0 else 1
            
            print(f"\nğŸš€ å¹¶è¡Œæ€§èƒ½åˆ†æ:")
            print(f"   - ä¸²è¡Œæ€»æ—¶é—´: {serial_time:.1f}ms")
            print(f"   - å¹¶è¡Œå®Œæˆæ—¶é—´: {parallel_time:.1f}ms")
            print(f"   - å®é™…åŠ é€Ÿæ¯”: {speedup:.2f}x")
            print(f"   - ç†è®ºåŠ é€Ÿæ¯”: {len(gpu_workers):.0f}x")
            print(f"   - å¹¶è¡Œæ•ˆç‡: {speedup/len(gpu_workers)*100:.1f}%")
        
        return results


def demo_parallel_ocr():
    """æ¼”ç¤ºå¹¶è¡ŒOCR"""
    
    print("ğŸ­ å¹¶è¡ŒOCRæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.ones((800, 1200, 3), dtype=np.uint8) * 255
    
    # åˆ›å»ºå¤šä¸ªæµ‹è¯•åŒºåŸŸ
    test_regions = []
    test_texts = []
    
    for i in range(20):  # åˆ›å»º20ä¸ªåŒºåŸŸ
        x = (i % 4) * 300 + 50
        y = (i // 4) * 150 + 50
        test_regions.append((x, y, x + 250, y + 100))
        
        text = f"Region {i+1}"
        test_texts.append(text)
        
        # åœ¨å›¾åƒä¸Šç»˜åˆ¶
        cv2.rectangle(test_image, (x, y), (x+250, y+100), (240, 240, 240), -1)
        cv2.putText(test_image, text, (x+10, y+50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 2)
    
    labels = [f"åŒºåŸŸ{i+1}" for i in range(len(test_regions))]
    
    # æµ‹è¯•ä¸åŒçš„å¹¶è¡Œæ–¹å¼
    
    # 1. çº¿ç¨‹æ± å¹¶è¡Œï¼ˆä½¿ç”¨2ä¸ªå·¥ä½œå™¨ï¼‰
    print("\n1. çº¿ç¨‹æ± å¹¶è¡Œ:")
    processor1 = ParallelRegionOCR(num_workers=2, use_gpu=False)
    results1 = processor1.recognize_regions_parallel_thread(test_image, test_regions, labels)
    
    # 2. è¿›ç¨‹æ± å¹¶è¡Œï¼ˆä½¿ç”¨4ä¸ªå·¥ä½œå™¨ï¼‰
    print("\n2. è¿›ç¨‹æ± å¹¶è¡Œ:")
    processor2 = ParallelRegionOCR(num_workers=4, use_gpu=False)
    results2 = processor2.recognize_regions_parallel_process(test_image, test_regions, labels)
    
    # 3. GPUæ‰¹å¤„ç†ï¼ˆå¦‚æœæœ‰GPUï¼‰
    print("\n3. GPUæ‰¹å¤„ç†:")
    try:
        processor3 = ParallelRegionOCR(use_gpu=True, gpu_ids=[0, 1])  # ä½¿ç”¨GPU 0å’Œ1
        results3 = processor3.recognize_regions_gpu_batch(test_image, test_regions, labels, batch_size=5)
    except:
        print("   âš ï¸ GPUä¸å¯ç”¨ï¼Œè·³è¿‡")
        results3 = []
    
    # æ¯”è¾ƒç»“æœ
    print("\nğŸ“Š ç»“æœå¯¹æ¯”:")
    print(f"   çº¿ç¨‹æ± ç»“æœæ•°: {len(results1)}")
    print(f"   è¿›ç¨‹æ± ç»“æœæ•°: {len(results2)}")
    if results3:
        print(f"   GPUæ‰¹å¤„ç†ç»“æœæ•°: {len(results3)}")


def benchmark_parallel_performance(image_path: str, num_regions: int = 50):
    """
    æ€§èƒ½åŸºå‡†æµ‹è¯•
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        num_regions: æµ‹è¯•åŒºåŸŸæ•°é‡
    """
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return
    
    h, w = image.shape[:2]
    
    # ç”ŸæˆéšæœºåŒºåŸŸ
    import random
    regions = []
    for _ in range(num_regions):
        x1 = random.randint(0, w - 100)
        y1 = random.randint(0, h - 50)
        x2 = min(x1 + random.randint(50, 200), w)
        y2 = min(y1 + random.randint(30, 100), h)
        regions.append((x1, y1, x2, y2))
    
    print(f"ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print(f"   - å›¾åƒ: {image_path}")
    print(f"   - åŒºåŸŸæ•°: {num_regions}")
    print("=" * 60)
    
    results = {}
    
    # æµ‹è¯•ä¸åŒé…ç½®
    configs = [
        ("å•çº¿ç¨‹", 1, False),
        ("2çº¿ç¨‹", 2, False),
        ("4çº¿ç¨‹", 4, False),
        ("8çº¿ç¨‹", 8, False),
    ]
    
    # å¦‚æœæœ‰GPUï¼Œæ·»åŠ GPUæµ‹è¯•
    try:
        import torch
        if torch.cuda.is_available():
            configs.append(("GPU", 1, True))
            if torch.cuda.device_count() > 1:
                configs.append((f"{torch.cuda.device_count()}GPU", torch.cuda.device_count(), True))
    except:
        pass
    
    for name, workers, use_gpu in configs:
        print(f"\næµ‹è¯• {name}:")
        processor = ParallelRegionOCR(num_workers=workers, use_gpu=use_gpu)
        
        start = time.time()
        if workers == 1:
            # å•çº¿ç¨‹ä½¿ç”¨çº¿ç¨‹æ± æ–¹æ³•
            _ = processor.recognize_regions_parallel_thread(image, regions)
        else:
            # å¤šçº¿ç¨‹/GPUä½¿ç”¨å¯¹åº”æ–¹æ³•
            if use_gpu:
                _ = processor.recognize_regions_gpu_batch(image, regions)
            else:
                _ = processor.recognize_regions_parallel_thread(image, regions)
        
        elapsed = time.time() - start
        results[name] = elapsed
        
        print(f"   è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"   é€Ÿåº¦: {num_regions/elapsed:.1f} åŒºåŸŸ/ç§’")
    
    # æ˜¾ç¤ºåŠ é€Ÿæ¯”
    print("\nğŸ¯ æ€§èƒ½æ€»ç»“:")
    baseline = results.get("å•çº¿ç¨‹", 1)
    for name, elapsed in results.items():
        speedup = baseline / elapsed
        print(f"   {name}: {elapsed:.2f}ç§’ (åŠ é€Ÿ {speedup:.2f}x)")


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    demo_parallel_ocr()
    
    # æ€§èƒ½æµ‹è¯•ï¼ˆéœ€è¦æä¾›çœŸå®å›¾åƒï¼‰
    # benchmark_parallel_performance("your_image.jpg", num_regions=100)
    
    print("\n" + "="*60)
    print("ä½¿ç”¨ç¤ºä¾‹:")
    print("="*60)
    print("""
from parallel_ocr_regions import ParallelRegionOCR
import cv2

# åˆå§‹åŒ–å¹¶è¡Œå¤„ç†å™¨
processor = ParallelRegionOCR(
    num_workers=4,        # ä½¿ç”¨4ä¸ªå·¥ä½œå™¨
    use_gpu=True,         # ä½¿ç”¨GPU
    gpu_ids=[0, 1]        # ä½¿ç”¨GPU 0å’Œ1
)

# è¯»å–å›¾åƒ
image = cv2.imread("image.jpg")

# å®šä¹‰åŒºåŸŸ
regions = [(x1,y1,x2,y2), ...]

# å¹¶è¡Œè¯†åˆ«
texts = processor.recognize_regions_parallel_thread(image, regions)
""")
