# -*- coding: utf-8 -*-
"""
UltraFast OCR æ ¸å¿ƒå®ç°
åŸºäºONNX Runtimeçš„è¶…å¿«é€ŸOCRå¼•æ“
"""

import os
import cv2
import numpy as np
import onnxruntime as ort
import time
from typing import List, Tuple, Optional
from pathlib import Path

from .preprocessing import ImagePreprocessor
from .postprocessing import TextDecoder
from .utils import validate_image, get_default_model_path


class UltraFastOCR:
    """
    è¶…å¿«é€ŸOCRå¼•æ“
    
    åŸºäºONNX Runtimeå®ç°ï¼Œæ— éœ€æ·±åº¦å­¦ä¹ æ¡†æ¶
    è¯†åˆ«é€Ÿåº¦ï¼š3-10ms
    """
    
    def __init__(self, 
                 det_model_path: Optional[str] = None,
                 rec_model_path: Optional[str] = None,
                 dict_path: Optional[str] = None,
                 use_gpu: bool = True,
                 providers: Optional[List[str]] = None,
                 enable_detection: bool = True,
                 fast_mode: bool = True):
        """
        åˆå§‹åŒ–OCRå¼•æ“
        
        Args:
            det_model_path: æ£€æµ‹æ¨¡å‹è·¯å¾„
            rec_model_path: è¯†åˆ«æ¨¡å‹è·¯å¾„
            dict_path: å­—ç¬¦å­—å…¸è·¯å¾„
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            providers: ONNX Runtime providers
            enable_detection: æ˜¯å¦å¯ç”¨æ£€æµ‹æ¨¡å‹ï¼ˆç”¨äºå¤šè¡Œæ–‡å­—ï¼‰
            fast_mode: å¿«é€Ÿæ¨¡å¼ï¼ˆç‰ºç‰²å°‘é‡ç²¾åº¦æ¢å–é€Ÿåº¦ï¼‰
        """
        
        # è®¾ç½®providers
        if providers is None:
            if use_gpu:
                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            else:
                providers = ['CPUExecutionProvider']
        
        # è·å–é»˜è®¤æ¨¡å‹è·¯å¾„
        if rec_model_path is None:
            rec_model_path = get_default_model_path('rec')
        if dict_path is None:
            dict_path = get_default_model_path('dict')
        if det_model_path is None:
            det_model_path = get_default_model_path('det')
        
        # éªŒè¯æ¨¡å‹æ–‡ä»¶
        if not os.path.exists(rec_model_path):
            raise FileNotFoundError(f"è¯†åˆ«æ¨¡å‹ä¸å­˜åœ¨: {rec_model_path}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.preprocessor = ImagePreprocessor()
        self.decoder = TextDecoder(dict_path)
        
        # åŠ è½½è¯†åˆ«æ¨¡å‹(å¿…éœ€)
        try:
            self.rec_session = ort.InferenceSession(rec_model_path, providers=providers)
            self.rec_input_name = self.rec_session.get_inputs()[0].name
            self.rec_input_shape = self.rec_session.get_inputs()[0].shape
            
            # æ‰“å°å®é™…ä½¿ç”¨çš„Provider
            actual_providers = self.rec_session.get_providers()
            if 'CUDAExecutionProvider' in actual_providers:
                print(f"âœ… OCRä½¿ç”¨GPUåŠ é€Ÿ: {actual_providers[0]}")
            else:
                print(f"âš ï¸ OCRä½¿ç”¨CPU: {actual_providers[0]}")
                
        except Exception as e:
            raise RuntimeError(f"åŠ è½½è¯†åˆ«æ¨¡å‹å¤±è´¥: {e}")
        
        # åŠ è½½æ£€æµ‹æ¨¡å‹(ç”¨äºå¤šè¡Œæ–‡å­—è¯†åˆ«)
        self.det_session = None
        self.enable_detection = enable_detection
        self.fast_mode = fast_mode
        
        if enable_detection:
            if det_model_path and os.path.exists(det_model_path):
                try:
                    # ä¸ºæ£€æµ‹æ¨¡å‹è®¾ç½®ä¼˜åŒ–çš„sessioné€‰é¡¹
                    sess_options = ort.SessionOptions()
                    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
                    sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL
                    sess_options.inter_op_num_threads = 4  # é™åˆ¶çº¿ç¨‹æ•°ä»¥æå‡æ•ˆç‡
                    sess_options.intra_op_num_threads = 4
                    
                    self.det_session = ort.InferenceSession(det_model_path, sess_options, providers=providers)
                    self.det_input_name = self.det_session.get_inputs()[0].name
                    self.det_input_shape = self.det_session.get_inputs()[0].shape
                    
                    mode_desc = "å¿«é€Ÿæ¨¡å¼" if self.fast_mode else "æ ‡å‡†æ¨¡å¼"
                    print(f"âœ… æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸï¼Œæ”¯æŒå¤šè¡Œæ–‡å­—è¯†åˆ« ({mode_desc})")
                except Exception as e:
                    print(f"âš ï¸ æ£€æµ‹æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                    print(f"   å°†é€€åŒ–ä¸ºå•è¡Œè¯†åˆ«æ¨¡å¼")
            else:
                print(f"âš ï¸ æ£€æµ‹æ¨¡å‹è·¯å¾„æ— æ•ˆ: {det_model_path}")
                print(f"   å¤šè¡Œæ–‡å­—è¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨")
        
        # é¢„çƒ­æ¨¡å‹
        self._warmup()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_calls = 0
        self.total_time = 0.0
    
    def _warmup(self):
        """æ¨¡å‹é¢„çƒ­"""
        try:
            # è¯†åˆ«æ¨¡å‹é¢„çƒ­
            if hasattr(self, 'rec_session'):
                dummy_input = np.zeros((1, 3, 48, 320), dtype=np.float32)
                _ = self.rec_session.run(None, {self.rec_input_name: dummy_input})
            
            # æ£€æµ‹æ¨¡å‹é¢„çƒ­
            if self.det_session:
                dummy_input = np.zeros((1, 3, 640, 640), dtype=np.float32)
                _ = self.det_session.run(None, {self.det_input_name: dummy_input})
                
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
    
    def recognize_single_line(self, 
                            image: np.ndarray, 
                            return_confidence: bool = False,
                            return_time: bool = False) -> Tuple:
        """
        è¯†åˆ«å•è¡Œæ–‡å­—
        
        Args:
            image: è¾“å…¥å›¾ç‰‡(BGRæ ¼å¼)
            return_confidence: æ˜¯å¦è¿”å›ç½®ä¿¡åº¦
            return_time: æ˜¯å¦è¿”å›è€—æ—¶
            
        Returns:
            æ ¹æ®å‚æ•°è¿”å› (text,) æˆ– (text, conf) æˆ– (text, conf, time_ms)
        """
        start_time = time.time()
        
        # éªŒè¯è¾“å…¥
        if not validate_image(image):
            if return_time and return_confidence:
                return "", 0.0, 0.0
            elif return_confidence:
                return "", 0.0
            else:
                return ""
        
        try:
            # é¢„å¤„ç†
            input_tensor = self.preprocessor.preprocess_for_recognition(image)
            
            # ONNXæ¨ç†
            outputs = self.rec_session.run(None, {self.rec_input_name: input_tensor})
            
            # åå¤„ç†
            text, confidence = self.decoder.decode_recognition(outputs[0])
            
            # ç»Ÿè®¡
            elapsed_time = (time.time() - start_time) * 1000
            self.total_calls += 1
            self.total_time += elapsed_time
            
            # è¿”å›ç»“æœ
            if return_time and return_confidence:
                return text, confidence, elapsed_time
            elif return_confidence:
                return text, confidence
            elif return_time:
                return text, elapsed_time
            else:
                return text
                
        except Exception as e:
            print(f"âŒ OCRè¯†åˆ«å¤±è´¥: {e}")
            if return_time and return_confidence:
                return "", 0.0, 0.0
            elif return_confidence:
                return "", 0.0
            else:
                return ""
    
    def recognize_multiline(self, 
                          image: np.ndarray,
                          return_boxes: bool = False,
                          return_confidence: bool = False,
                          min_confidence: float = 0.5,
                          sort_output: bool = True) -> List:
        """
        è¯†åˆ«å¤šè¡Œæ–‡å­—ï¼ˆå®Œæ•´çš„æ£€æµ‹+è¯†åˆ«æµç¨‹ï¼‰
        
        Args:
            image: è¾“å…¥å›¾ç‰‡
            return_boxes: æ˜¯å¦è¿”å›æ–‡å­—æ¡†åæ ‡
            return_confidence: æ˜¯å¦è¿”å›ç½®ä¿¡åº¦
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            sort_output: æ˜¯å¦æŒ‰ä½ç½®æ’åºï¼ˆä»ä¸Šåˆ°ä¸‹ï¼Œä»å·¦åˆ°å³ï¼‰
            
        Returns:
            æ ¹æ®å‚æ•°è¿”å›ä¸åŒæ ¼å¼ï¼š
            - é»˜è®¤: ['æ–‡å­—1', 'æ–‡å­—2', ...]
            - return_boxes=True: [('æ–‡å­—', ç½®ä¿¡åº¦, [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]), ...]
            - return_confidence=True: [('æ–‡å­—', ç½®ä¿¡åº¦), ...]
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹æ¨¡å‹
        if self.det_session is None:
            # æ²¡æœ‰æ£€æµ‹æ¨¡å‹ï¼Œé€€åŒ–ä¸ºå•è¡Œå¤„ç†
            print("âš ï¸ æ— æ£€æµ‹æ¨¡å‹ï¼Œä½¿ç”¨å•è¡Œè¯†åˆ«æ¨¡å¼")
            if return_confidence:
                text, conf = self.recognize_single_line(image, return_confidence=True)
                if text and conf >= min_confidence:
                    if return_boxes:
                        h, w = image.shape[:2]
                        return [(text, conf, [[0, 0], [w, 0], [w, h], [0, h]])]
                    else:
                        return [(text, conf)]
            else:
                text = self.recognize_single_line(image)
                if text:
                    if return_boxes:
                        h, w = image.shape[:2]
                        return [(text, 0.95, [[0, 0], [w, 0], [w, h], [0, h]])]
                    else:
                        return [text]
            return []
        
        start_time = time.time()
        
        try:
            # ========== æ­¥éª¤1: æ–‡å­—æ£€æµ‹ ==========
            print("ğŸ” æ‰§è¡Œæ–‡å­—æ£€æµ‹...")
            det_start = time.time()
            
            # é¢„å¤„ç†å›¾ç‰‡ç”¨äºæ£€æµ‹ï¼ˆä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼‰
            det_input, ratio = self.preprocessor.preprocess_for_detection(
                image, 
                max_side=640 if self.fast_mode else 960,
                fast_mode=self.fast_mode
            )
            
            # è¿è¡Œæ£€æµ‹æ¨¡å‹
            det_outputs = self.det_session.run(None, {self.det_input_name: det_input})
            
            # è§£ç æ£€æµ‹ç»“æœ
            boxes = self.preprocessor.decode_detection(det_outputs[0], ratio)
            
            det_time = (time.time() - det_start) * 1000
            print(f"   æ£€æµ‹åˆ° {len(boxes)} ä¸ªæ–‡å­—åŒºåŸŸ ({det_time:.1f}ms)")
            
            if not boxes:
                print("   æœªæ£€æµ‹åˆ°æ–‡å­—åŒºåŸŸ")
                return []
            
            # ========== æ­¥éª¤2: æ’åºæ£€æµ‹æ¡† ==========
            if sort_output and len(boxes) > 1:
                # æŒ‰yåæ ‡(ä»ä¸Šåˆ°ä¸‹)ï¼Œç„¶åxåæ ‡(ä»å·¦åˆ°å³)æ’åº
                sorted_boxes = []
                for box in boxes:
                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x = np.mean(box[:, 0])
                    center_y = np.mean(box[:, 1])
                    sorted_boxes.append((center_y, center_x, box))
                
                # æ’åºï¼šå…ˆæŒ‰yï¼Œå†æŒ‰x
                sorted_boxes.sort(key=lambda x: (x[0], x[1]))
                boxes = [item[2] for item in sorted_boxes]
            
            # ========== æ­¥éª¤3: é€è¡Œè¯†åˆ« ==========
            print(f"ğŸ“– è¯†åˆ« {len(boxes)} è¡Œæ–‡å­—...")
            rec_start = time.time()
            
            results = []
            for i, box in enumerate(boxes):
                # è£å‰ªæ–‡å­—åŒºåŸŸ
                roi = self.preprocessor.crop_image_by_box(image, box)
                
                if roi.size == 0:
                    continue
                
                # è¯†åˆ«å•è¡Œæ–‡å­—
                text, confidence = self.recognize_single_line(roi, return_confidence=True)
                
                # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
                if text and confidence >= min_confidence:
                    # æ ¹æ®å‚æ•°è¿”å›ä¸åŒæ ¼å¼
                    if return_boxes:
                        results.append((text, confidence, box.tolist()))
                    elif return_confidence:
                        results.append((text, confidence))
                    else:
                        results.append(text)
                    
                    print(f"   è¡Œ{i+1}: '{text[:30]}...' (ç½®ä¿¡åº¦: {confidence:.3f})")
            
            rec_time = (time.time() - rec_start) * 1000
            total_time = (time.time() - start_time) * 1000
            
            print(f"   è¯†åˆ«å®Œæˆ ({rec_time:.1f}ms)")
            print(f"âœ… å¤šè¡Œè¯†åˆ«æ€»è€—æ—¶: {total_time:.1f}ms")
            
            return results
            
        except Exception as e:
            print(f"âŒ å¤šè¡Œè¯†åˆ«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def recognize(self, 
                 image: np.ndarray, 
                 single_line: bool = True,
                 **kwargs) -> str:
        """
        é€šç”¨è¯†åˆ«æ¥å£
        
        Args:
            image: è¾“å…¥å›¾ç‰‡
            single_line: æ˜¯å¦å•è¡Œæ¨¡å¼
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            è¯†åˆ«çš„æ–‡å­—
        """
        if single_line:
            return self.recognize_single_line(image, **kwargs)
        else:
            results = self.recognize_multiline(image, return_boxes=False)
            return ' '.join(results)
    
    def batch_recognize(self, 
                       images: List[np.ndarray],
                       single_line: bool = True) -> List[str]:
        """
        æ‰¹é‡è¯†åˆ«
        
        Args:
            images: å›¾ç‰‡åˆ—è¡¨
            single_line: æ˜¯å¦å•è¡Œæ¨¡å¼
            
        Returns:
            è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        results = []
        for image in images:
            if single_line:
                text = self.recognize_single_line(image)
            else:
                texts = self.recognize_multiline(image, return_boxes=False)
                text = ' '.join(texts)
            results.append(text)
        return results
    
    def benchmark(self, 
                 test_images: List[np.ndarray],
                 rounds: int = 100) -> dict:
        """
        æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        Args:
            test_images: æµ‹è¯•å›¾ç‰‡åˆ—è¡¨
            rounds: æµ‹è¯•è½®æ•°
            
        Returns:
            æ€§èƒ½ç»Ÿè®¡
        """
        if not test_images:
            return {}
        
        # é¢„çƒ­
        for _ in range(3):
            _ = self.recognize_single_line(test_images[0])
        
        # æµ‹è¯•
        times = []
        for _ in range(rounds):
            for img in test_images:
                start = time.time()
                _ = self.recognize_single_line(img)
                times.append((time.time() - start) * 1000)
        
        times = np.array(times)
        
        return {
            'num_images': len(test_images),
            'rounds': rounds,
            'total_calls': len(times),
            'avg_time_ms': float(np.mean(times)),
            'min_time_ms': float(np.min(times)),
            'max_time_ms': float(np.max(times)),
            'std_time_ms': float(np.std(times)),
            'fps': float(1000 / np.mean(times)),
            'percentile_95_ms': float(np.percentile(times, 95)),
            'percentile_99_ms': float(np.percentile(times, 99))
        }
    
    def get_statistics(self) -> dict:
        """è·å–ä½¿ç”¨ç»Ÿè®¡"""
        if self.total_calls == 0:
            return {
                'total_calls': 0,
                'avg_time_ms': 0,
                'total_time_ms': 0
            }
        
        return {
            'total_calls': self.total_calls,
            'avg_time_ms': self.total_time / self.total_calls,
            'total_time_ms': self.total_time,
            'estimated_fps': 1000 / (self.total_time / self.total_calls) if self.total_calls > 0 else 0
        }
    
    def __repr__(self):
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"UltraFastOCR(calls={self.total_calls}, avg_time={self.total_time/max(1,self.total_calls):.2f}ms)"
    
    def __del__(self):
        """ææ„å‡½æ•°"""
        # æ¸…ç†ONNX Session
        if hasattr(self, 'rec_session'):
            del self.rec_session
        if hasattr(self, 'det_session') and self.det_session:
            del self.det_session
