# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ‰¹é‡OCRå¤„ç†å™¨çš„ä½¿ç”¨ç¤ºä¾‹
"""

import cv2
import numpy as np
import sys
from pathlib import Path

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))

from batch_ocr_processor import BatchOCRProcessor, TextRegion
from fast_text_line_splitter import ProjectionLineSplitter

def test_batch_ocr_with_real_image():
    """ä½¿ç”¨çœŸå®å›¾ç‰‡æµ‹è¯•æ‰¹é‡OCR"""
    
    print("ğŸš€ æ‰¹é‡OCRå¤„ç†æµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç»„ä»¶
    batch_processor = BatchOCRProcessor(
        max_batch_size=32,
        target_height=48,  # ç›®æ ‡é«˜åº¦
        padding=5  # åŒºåŸŸé—´éš”
    )
    line_splitter = ProjectionLineSplitter()
    
    # è¯»å–æµ‹è¯•å›¾ç‰‡ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å®é™…å›¾ç‰‡è·¯å¾„ï¼‰
    image_path = "your_test_image.jpg"  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    
    # å¦‚æœæ²¡æœ‰çœŸå®å›¾ç‰‡ï¼Œåˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡
    if not Path(image_path).exists():
        print("åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•å›¾ç‰‡...")
        image = create_test_image()
    else:
        image = cv2.imread(image_path)
    
    # æ¨¡æ‹ŸYOLOæ£€æµ‹ç»“æœï¼ˆå®é™…ä½¿ç”¨æ—¶ä»YOLOè·å–ï¼‰
    detections = [
        {
            'class': 'chat_area',
            'bbox': [50, 50, 400, 200],  # x1, y1, x2, y2
            'confidence': 0.95
        },
        {
            'class': 'input_area',
            'bbox': [50, 250, 400, 320],
            'confidence': 0.92
        },
        {
            'class': 'button_area',
            'bbox': [50, 350, 200, 400],
            'confidence': 0.88
        }
    ]
    
    # æ‰§è¡Œæ‰¹é‡OCRå¤„ç†
    result = batch_processor.process_im_image_batch(
        image=image,
        yolo_detections=detections,
        line_splitter=line_splitter
    )
    
    # æ˜¾ç¤ºç»“æœ
    if result['success']:
        print("\nâœ… æ‰¹é‡OCRå¤„ç†æˆåŠŸï¼")
        print(f"ç»Ÿè®¡ä¿¡æ¯ï¼š")
        stats = result['stats']
        print(f"  - OCRè°ƒç”¨æ¬¡æ•°: {stats['ocr_calls']} æ¬¡")
        print(f"  - å¤„ç†åŒºåŸŸæ•°: {stats['total_regions']}")
        print(f"  - æ€»è€—æ—¶: {stats['total_time_ms']:.1f}ms")
        print(f"  - å¹³å‡è€—æ—¶: {stats['avg_time_per_region']:.1f}ms/åŒºåŸŸ")
        
        print("\nè¯†åˆ«ç»“æœï¼š")
        for source_type, regions in result['results'].items():
            print(f"\n{source_type}:")
            for region in regions:
                print(f"  - {region['region_id']}: {region['text']}")
                print(f"    ç½®ä¿¡åº¦: {region['confidence']:.3f}")
                print(f"    ä½ç½®: {region['bbox']}")
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        batch_processor.save_batch_visualization(result, "batch_ocr_output")
        print("\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° batch_ocr_output/ ç›®å½•")
    else:
        print(f"âŒ å¤„ç†å¤±è´¥: {result.get('message', 'Unknown error')}")

def test_direct_text_regions():
    """ç›´æ¥æä¾›æ–‡å­—åŒºåŸŸè¿›è¡Œæ‰¹é‡OCR"""
    
    print("\nğŸ”§ ç›´æ¥æ–‡å­—åŒºåŸŸæ‰¹é‡å¤„ç†")
    print("=" * 60)
    
    batch_processor = BatchOCRProcessor()
    
    # åˆ›å»ºä¸€äº›æµ‹è¯•æ–‡å­—åŒºåŸŸ
    text_regions = []
    
    # æ¨¡æ‹Ÿå¤šä¸ªæ–‡å­—è¡ŒåŒºåŸŸ
    for i in range(5):
        # åˆ›å»ºæ¨¡æ‹Ÿçš„æ–‡å­—å›¾ç‰‡
        text_img = np.ones((30, 150, 3), dtype=np.uint8) * 255
        cv2.putText(text_img, f"Text Line {i+1}", (10, 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)
        
        region = TextRegion(
            region_id=f"region_{i+1}",
            bbox=(0, i*40, 150, i*40+30),
            image_crop=text_img,
            source_type="test",
            confidence=0.9
        )
        text_regions.append(region)
    
    # åˆ›å»ºæ‰¹å¤„ç†å›¾åƒ
    batch_image, region_mappings = batch_processor.create_batch_image(text_regions)
    
    print(f"æ‰¹å¤„ç†å›¾åƒå°ºå¯¸: {batch_image.shape}")
    print(f"åŒ…å«åŒºåŸŸæ•°: {len(region_mappings)}")
    
    # æ‰§è¡ŒOCRè¯†åˆ«
    results = batch_processor.simulate_ocr_recognition(batch_image, region_mappings)
    
    print("\nè¯†åˆ«ç»“æœ:")
    for result in results:
        print(f"  {result.region_id}: {result.text_content}")
        print(f"    ç½®ä¿¡åº¦: {result.confidence:.3f}")
    
    # æ˜¾ç¤ºæ€§èƒ½ä¼˜åŠ¿
    print(f"\nğŸ¯ æ€§èƒ½ä¼˜åŠ¿:")
    print(f"  ä¼ ç»Ÿæ–¹æ³•: {len(text_regions)} æ¬¡OCRè°ƒç”¨")
    print(f"  æ‰¹é‡æ–¹æ³•: 1 æ¬¡OCRè°ƒç”¨")
    print(f"  ç†è®ºåŠ é€Ÿ: {len(text_regions)}x")

def create_test_image():
    """åˆ›å»ºæµ‹è¯•å›¾ç‰‡"""
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„èŠå¤©ç•Œé¢å›¾ç‰‡
    img = np.ones((500, 450, 3), dtype=np.uint8) * 240
    
    # æ·»åŠ ä¸€äº›æ–‡å­—åŒºåŸŸ
    texts = [
        ("èŠå¤©åŒºåŸŸ - æ¶ˆæ¯1", (60, 80)),
        ("èŠå¤©åŒºåŸŸ - æ¶ˆæ¯2", (60, 120)),
        ("èŠå¤©åŒºåŸŸ - æ¶ˆæ¯3", (60, 160)),
        ("è¾“å…¥æ¡†æ–‡å­—", (60, 280)),
        ("å‘é€æŒ‰é’®", (80, 370))
    ]
    
    for text, (x, y) in texts:
        cv2.putText(img, text, (x, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
    
    return img

if __name__ == "__main__":
    # æµ‹è¯•æ‰¹é‡OCRå¤„ç†
    test_batch_ocr_with_real_image()
    
    # æµ‹è¯•ç›´æ¥å¤„ç†æ–‡å­—åŒºåŸŸ
    test_direct_text_regions()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
