# -*- coding: utf-8 -*-
"""
IMåŒºåŸŸæ–‡å­—æå–æµ‹è¯•
æ¨¡æ‹ŸYOLOæ£€æµ‹åˆ°èŠå¤©æ¡†/è¾“å…¥æ¡†åï¼Œç›´æ¥æå–å…¶ä¸­çš„æ–‡å­—è¡Œ
æ— éœ€é¢å¤–æ ‡æ³¨æ¯ä¸€è¡Œæ–‡å­—
"""

import cv2
import numpy as np
import time
from PIL import Image, ImageDraw, ImageFont
from typing import List, Tuple, Dict
import os
import sys
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from fast_text_line_splitter import ProjectionLineSplitter, TextLine


class IMRegionTextExtractor:
    """IMåŒºåŸŸæ–‡å­—æå–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.line_splitter = ProjectionLineSplitter()
        self.font_path = self._find_chinese_font()
    
    def _find_chinese_font(self) -> str:
        """å¯»æ‰¾ç³»ç»Ÿä¸­çš„ä¸­æ–‡å­—ä½“"""
        font_candidates = [
            "/System/Library/Fonts/PingFang.ttc",  # macOS
            "/System/Library/Fonts/STHeiti Medium.ttc",  # macOSå¤‡é€‰
            "C:/Windows/Fonts/simsun.ttc",  # Windows
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",  # Linux
        ]
        
        for font in font_candidates:
            if os.path.exists(font):
                return font
        return None
    
    def create_realistic_im_scenarios(self) -> Dict[str, Tuple[np.ndarray, List[Dict]]]:
        """åˆ›å»ºçœŸå®çš„IMåœºæ™¯ï¼ŒåŒ…å«å›¾åƒå’Œæ¨¡æ‹Ÿçš„YOLOæ£€æµ‹ç»“æœ"""
        
        scenarios = {}
        
        # åœºæ™¯1: å¾®ä¿¡èŠå¤©ç•Œé¢
        scenarios['å¾®ä¿¡ç•Œé¢'] = self._create_wechat_interface()
        
        # åœºæ™¯2: QQèŠå¤©ç•Œé¢  
        scenarios['QQç•Œé¢'] = self._create_qq_interface()
        
        # åœºæ™¯3: é’‰é’‰å·¥ä½œç•Œé¢
        scenarios['é’‰é’‰ç•Œé¢'] = self._create_dingtalk_interface()
        
        # åœºæ™¯4: å¤æ‚èŠå¤©ç•Œé¢ï¼ˆå¤šç§å…ƒç´ ï¼‰
        scenarios['å¤æ‚ç•Œé¢'] = self._create_complex_interface()
        
        return scenarios
    
    def _create_wechat_interface(self) -> Tuple[np.ndarray, List[Dict]]:
        """åˆ›å»ºå¾®ä¿¡é£æ ¼çš„èŠå¤©ç•Œé¢"""
        
        # åˆ›å»º800x600çš„æ‰‹æœºå±å¹•
        img = Image.new('RGB', (800, 600), (237, 237, 237))  # å¾®ä¿¡ç°è‰²èƒŒæ™¯
        draw = ImageDraw.Draw(img)
        
        # åŠ è½½å­—ä½“
        try:
            if self.font_path:
                font_normal = ImageFont.truetype(self.font_path, 28)
                font_small = ImageFont.truetype(self.font_path, 20)
            else:
                font_normal = ImageFont.load_default()
                font_small = ImageFont.load_default()
        except:
            font_normal = ImageFont.load_default()
            font_small = ImageFont.load_default()
        
        # ç»˜åˆ¶é¡¶éƒ¨çŠ¶æ€æ 
        draw.rectangle([0, 0, 800, 80], fill=(64, 64, 64))
        draw.text((20, 25), "å¾®ä¿¡", font=font_normal, fill=(255, 255, 255))
        
        # ç»˜åˆ¶èŠå¤©åŒºåŸŸèƒŒæ™¯
        chat_bg_color = (255, 255, 255)
        draw.rectangle([20, 100, 780, 450], fill=chat_bg_color, outline=(200, 200, 200), width=2)
        
        # ç»˜åˆ¶èŠå¤©æ¶ˆæ¯ï¼ˆå¸¦æ°”æ³¡æ•ˆæœï¼‰
        messages = [
            {"text": "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”ä¸é”™", "type": "received", "y": 120},
            {"text": "æ˜¯çš„ï¼Œå¾ˆé€‚åˆå‡ºå»èµ°èµ°", "type": "sent", "y": 170},
            {"text": "æˆ‘ä»¬å»å…¬å›­æ•£æ­¥æ€ä¹ˆæ ·ï¼Ÿ", "type": "received", "y": 220},
            {"text": "å¥½ä¸»æ„ï¼å‡ ç‚¹è§é¢ï¼Ÿ", "type": "sent", "y": 270},
            {"text": "ä¸‹åˆä¸¤ç‚¹åœ¨å…¬å›­é—¨å£", "type": "received", "y": 320},
            {"text": "æ²¡é—®é¢˜ï¼Œåˆ°æ—¶å€™è§", "type": "sent", "y": 370},
        ]
        
        for msg in messages:
            if msg["type"] == "received":
                # å·¦ä¾§æ¥æ”¶æ¶ˆæ¯ - ç™½è‰²æ°”æ³¡
                bubble_x1, bubble_x2 = 40, 400
                bubble_color = (255, 255, 255)
                text_color = (0, 0, 0)
            else:
                # å³ä¾§å‘é€æ¶ˆæ¯ - ç»¿è‰²æ°”æ³¡
                bubble_x1, bubble_x2 = 420, 760
                bubble_color = (162, 218, 87)
                text_color = (0, 0, 0)
            
            # ç»˜åˆ¶æ°”æ³¡èƒŒæ™¯ï¼ˆåœ†è§’çŸ©å½¢æ•ˆæœï¼‰
            draw.rounded_rectangle([bubble_x1, msg["y"], bubble_x2, msg["y"] + 40], 
                                 radius=15, fill=bubble_color, outline=(180, 180, 180))
            
            # ç»˜åˆ¶æ–‡å­—
            draw.text((bubble_x1 + 15, msg["y"] + 8), msg["text"], 
                     font=font_normal, fill=text_color)
        
        # ç»˜åˆ¶è¾“å…¥æ¡†åŒºåŸŸ
        input_bg_color = (248, 248, 248)
        draw.rectangle([20, 470, 780, 580], fill=input_bg_color, outline=(200, 200, 200), width=2)
        
        # è¾“å…¥æ¡†
        draw.rectangle([40, 490, 600, 540], fill=(255, 255, 255), outline=(180, 180, 180), width=1)
        draw.text((60, 505), "æ­£åœ¨è¾“å…¥æ¶ˆæ¯...", font=font_normal, fill=(150, 150, 150))
        
        # å‘é€æŒ‰é’®
        draw.rectangle([620, 490, 720, 540], fill=(87, 168, 87), outline=(70, 150, 70))
        draw.text((650, 505), "å‘é€", font=font_normal, fill=(255, 255, 255))
        
        # è½¬æ¢ä¸ºOpenCVæ ¼å¼
        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        
        # æ¨¡æ‹ŸYOLOæ£€æµ‹ç»“æœ
        yolo_detections = [
            {
                'class': 'chat_area',
                'bbox': [20, 100, 780, 450],  # èŠå¤©åŒºåŸŸ
                'confidence': 0.95
            },
            {
                'class': 'input_area', 
                'bbox': [20, 470, 780, 580],  # è¾“å…¥åŒºåŸŸ
                'confidence': 0.92
            }
        ]
        
        return cv_img, yolo_detections
    
    def _create_qq_interface(self) -> Tuple[np.ndarray, List[Dict]]:
        """åˆ›å»ºQQé£æ ¼çš„èŠå¤©ç•Œé¢"""
        
        img = Image.new('RGB', (800, 600), (240, 240, 245))  # QQè“ç°è‰²èƒŒæ™¯
        draw = ImageDraw.Draw(img)
        
        try:
            if self.font_path:
                font_normal = ImageFont.truetype(self.font_path, 26)
                font_small = ImageFont.truetype(self.font_path, 18)
            else:
                font_normal = ImageFont.load_default()
                font_small = ImageFont.load_default()
        except:
            font_normal = ImageFont.load_default()
            font_small = ImageFont.load_default()
        
        # QQé¡¶éƒ¨
        draw.rectangle([0, 0, 800, 80], fill=(18, 183, 245))
        draw.text((20, 25), "QQèŠå¤©", font=font_normal, fill=(255, 255, 255))
        
        # èŠå¤©åŒºåŸŸ
        draw.rectangle([10, 90, 790, 460], fill=(255, 255, 255), outline=(180, 180, 180))
        
        # QQæ¶ˆæ¯ï¼ˆä¸åŒæ ·å¼ï¼‰
        messages = [
            "å°æ˜ 14:20",
            "å¤§å®¶æ™šä¸Šä¸€èµ·åƒé¥­å—ï¼Ÿ",
            "å°çº¢ 14:22", 
            "å¯ä»¥å•Šï¼Œå»å“ªé‡Œåƒï¼Ÿ",
            "å°æ 14:23",
            "æˆ‘æ¨èé‚£å®¶å·èœé¦†",
            "å°æ˜ 14:25",
            "å¥½çš„ï¼Œé‚£å°±6ç‚¹åŠè§"
        ]
        
        y_pos = 110
        for i, msg in enumerate(messages):
            if ":" in msg and len(msg) < 20:  # æ˜µç§°å’Œæ—¶é—´
                draw.text((30, y_pos), msg, font=font_small, fill=(120, 120, 120))
                y_pos += 25
            else:  # æ¶ˆæ¯å†…å®¹
                draw.text((50, y_pos), msg, font=font_normal, fill=(0, 0, 0))
                y_pos += 40
        
        # è¾“å…¥åŒºåŸŸ
        draw.rectangle([10, 470, 790, 590], fill=(250, 250, 250), outline=(180, 180, 180))
        draw.rectangle([30, 490, 650, 540], fill=(255, 255, 255), outline=(150, 150, 150))
        draw.text((50, 505), "è¯·è¾“å…¥æ¶ˆæ¯", font=font_normal, fill=(180, 180, 180))
        
        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        
        yolo_detections = [
            {
                'class': 'chat_area',
                'bbox': [10, 90, 790, 460],
                'confidence': 0.93
            },
            {
                'class': 'input_area',
                'bbox': [10, 470, 790, 590], 
                'confidence': 0.89
            }
        ]
        
        return cv_img, yolo_detections
    
    def _create_dingtalk_interface(self) -> Tuple[np.ndarray, List[Dict]]:
        """åˆ›å»ºé’‰é’‰å·¥ä½œç•Œé¢"""
        
        img = Image.new('RGB', (800, 600), (245, 245, 245))
        draw = ImageDraw.Draw(img)
        
        try:
            if self.font_path:
                font_normal = ImageFont.truetype(self.font_path, 24)
                font_small = ImageFont.truetype(self.font_path, 18)
            else:
                font_normal = ImageFont.load_default()
                font_small = ImageFont.load_default()
        except:
            font_normal = ImageFont.load_default()
            font_small = ImageFont.load_default()
        
        # é’‰é’‰é¡¶éƒ¨
        draw.rectangle([0, 0, 800, 80], fill=(0, 138, 255))
        draw.text((20, 25), "å·¥ä½œç¾¤èŠ", font=font_normal, fill=(255, 255, 255))
        
        # å·¥ä½œæ¶ˆæ¯åŒºåŸŸ
        draw.rectangle([15, 90, 785, 450], fill=(255, 255, 255))
        
        work_messages = [
            "ã€é‡è¦é€šçŸ¥ã€‘é¡¹ç›®è¯„å®¡å®‰æ’",
            "æ—¶é—´ï¼šæ˜å¤©ä¸‹åˆ2:00-5:00",
            "åœ°ç‚¹ï¼šAåº§ä¼šè®®å®¤301", 
            "è¯·å‡†å¤‡ä»¥ä¸‹ææ–™ï¼š",
            "1. é¡¹ç›®è¿›åº¦æŠ¥å‘Š",
            "2. æŠ€æœ¯æ–‡æ¡£å’Œä»£ç ",
            "3. æµ‹è¯•ç»“æœæˆªå›¾",
            "è¯·å„ä½åŒäº‹æŒ‰æ—¶å‚åŠ "
        ]
        
        y_pos = 110
        for msg in work_messages:
            # å·¥ä½œæ¶ˆæ¯ç”¨ä¸åŒé¢œè‰²æ ‡è¯†
            if "ã€" in msg:
                draw.text((35, y_pos), msg, font=font_normal, fill=(255, 0, 0))  # é‡è¦æ¶ˆæ¯çº¢è‰²
            elif msg.startswith(("æ—¶é—´", "åœ°ç‚¹")):
                draw.text((35, y_pos), msg, font=font_normal, fill=(0, 100, 0))  # å…³é”®ä¿¡æ¯ç»¿è‰²
            else:
                draw.text((35, y_pos), msg, font=font_normal, fill=(0, 0, 0))
            y_pos += 35
        
        # è¾“å…¥åŒºåŸŸ
        draw.rectangle([15, 460, 785, 580], fill=(248, 248, 248))
        draw.rectangle([35, 480, 650, 530], fill=(255, 255, 255), outline=(200, 200, 200))
        draw.text((55, 495), "è¾“å…¥å·¥ä½œæ¶ˆæ¯", font=font_normal, fill=(150, 150, 150))
        
        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        
        yolo_detections = [
            {
                'class': 'chat_area',
                'bbox': [15, 90, 785, 450],
                'confidence': 0.96
            },
            {
                'class': 'input_area',
                'bbox': [15, 460, 785, 580],
                'confidence': 0.94
            }
        ]
        
        return cv_img, yolo_detections
    
    def _create_complex_interface(self) -> Tuple[np.ndarray, List[Dict]]:
        """åˆ›å»ºå¤æ‚çš„èŠå¤©ç•Œé¢ï¼ˆæ¨¡æ‹ŸçœŸå®å¤æ‚åœºæ™¯ï¼‰"""
        
        img = Image.new('RGB', (800, 600), (235, 235, 235))
        draw = ImageDraw.Draw(img)
        
        try:
            if self.font_path:
                font_normal = ImageFont.truetype(self.font_path, 22)
                font_small = ImageFont.truetype(self.font_path, 16)
            else:
                font_normal = ImageFont.load_default()
                font_small = ImageFont.load_default()
        except:
            font_normal = ImageFont.load_default()
            font_small = ImageFont.load_default()
        
        # å¤æ‚ç•Œé¢é¡¶éƒ¨
        draw.rectangle([0, 0, 800, 70], fill=(50, 50, 50))
        draw.text((20, 20), "å¤æ‚èŠå¤©ç•Œé¢", font=font_normal, fill=(255, 255, 255))
        
        # ä¸»èŠå¤©åŒºåŸŸ - æœ‰å¤šç§èƒŒæ™¯è‰²
        draw.rectangle([20, 80, 780, 350], fill=(250, 250, 250))
        
        # ä¸åŒèƒŒæ™¯è‰²çš„æ¶ˆæ¯
        complex_messages = [
            {"text": "è¿™æ˜¯æ™®é€šæ¶ˆæ¯", "bg": (255, 255, 255), "y": 100},
            {"text": "è¿™æ˜¯é‡è¦æé†’æ¶ˆæ¯", "bg": (255, 240, 240), "y": 140},
            {"text": "è¿™æ˜¯ç³»ç»Ÿé€šçŸ¥æ¶ˆæ¯", "bg": (240, 255, 240), "y": 180},
            {"text": "Hello mixed English", "bg": (240, 240, 255), "y": 220},
            {"text": "åŒ…å«æ•°å­—123å’Œç¬¦å·!@#", "bg": (255, 255, 240), "y": 260},
            {"text": "æœ€åä¸€æ¡æ¶ˆæ¯æµ‹è¯•", "bg": (255, 255, 255), "y": 300}
        ]
        
        for msg in complex_messages:
            # ç»˜åˆ¶ä¸åŒèƒŒæ™¯è‰²çš„æ¶ˆæ¯æ¡†
            draw.rectangle([40, msg["y"], 740, msg["y"] + 30], 
                          fill=msg["bg"], outline=(200, 200, 200))
            draw.text((60, msg["y"] + 5), msg["text"], font=font_normal, fill=(0, 0, 0))
        
        # ä¾§è¾¹ä¿¡æ¯åŒºåŸŸ
        draw.rectangle([20, 360, 780, 440], fill=(245, 245, 250))
        side_info = ["åœ¨çº¿ç”¨æˆ·: 5äºº", "ç¾¤æ–‡ä»¶: 10ä¸ª", "ç¾¤å…¬å‘Š: æŸ¥çœ‹è¯¦æƒ…"]
        y_pos = 375
        for info in side_info:
            draw.text((40, y_pos), info, font=font_small, fill=(100, 100, 100))
            y_pos += 25
        
        # åº•éƒ¨è¾“å…¥åŒºåŸŸ
        draw.rectangle([20, 450, 780, 580], fill=(248, 248, 248))
        draw.rectangle([40, 470, 600, 520], fill=(255, 255, 255), outline=(180, 180, 180))
        draw.text((60, 485), "å¤æ‚ç•Œé¢è¾“å…¥æµ‹è¯•...", font=font_normal, fill=(120, 120, 120))
        
        # å·¥å…·æŒ‰é’®åŒºåŸŸ
        draw.rectangle([40, 530, 740, 560], fill=(240, 240, 240))
        draw.text((60, 535), "è¡¨æƒ…  æ–‡ä»¶  å›¾ç‰‡  è¯­éŸ³", font=font_small, fill=(80, 80, 80))
        
        cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        
        yolo_detections = [
            {
                'class': 'chat_area',
                'bbox': [20, 80, 780, 350],
                'confidence': 0.88
            },
            {
                'class': 'side_info',
                'bbox': [20, 360, 780, 440],
                'confidence': 0.75
            },
            {
                'class': 'input_area', 
                'bbox': [20, 450, 780, 580],
                'confidence': 0.91
            }
        ]
        
        return cv_img, yolo_detections
    
    def extract_text_from_regions(self, image: np.ndarray, 
                                 yolo_detections: List[Dict],
                                 target_classes: List[str] = None) -> Dict:
        """ä»YOLOæ£€æµ‹çš„åŒºåŸŸä¸­æå–æ–‡å­—è¡Œ"""
        
        if target_classes is None:
            target_classes = ['chat_area', 'input_area', 'side_info']
        
        results = {}
        total_time = 0
        
        print(f"ğŸ” å¼€å§‹å¤„ç† {len(yolo_detections)} ä¸ªæ£€æµ‹åŒºåŸŸ...")
        
        for detection in yolo_detections:
            class_name = detection['class']
            bbox = detection['bbox']
            confidence = detection.get('confidence', 0.0)
            
            if class_name not in target_classes:
                continue
            
            print(f"\nğŸ“ å¤„ç†åŒºåŸŸ: {class_name}")
            print(f"   ä½ç½®: {bbox}")
            print(f"   ç½®ä¿¡åº¦: {confidence:.2f}")
            
            # è£å‰ªåŒºåŸŸ
            x1, y1, x2, y2 = bbox
            region = image[y1:y2, x1:x2]
            
            if region.size == 0:
                continue
            
            # å›¾åƒé¢„å¤„ç†å¢å¼ºï¼ˆå¯é€‰ï¼‰
            enhanced_region = self._enhance_region_contrast(region)
            
            # ä½¿ç”¨æŠ•å½±æ³•åˆ†å‰²æ–‡å­—è¡Œ
            start_time = time.time()
            lines = self.line_splitter._projection_method(enhanced_region)
            elapsed_time = (time.time() - start_time) * 1000
            total_time += elapsed_time
            
            print(f"   æ£€æµ‹åˆ° {len(lines)} è¡Œæ–‡å­—")
            print(f"   åˆ†å‰²è€—æ—¶: {elapsed_time:.1f}ms")
            
            # æ•´ç†ç»“æœ
            region_result = {
                'class': class_name,
                'bbox': bbox,
                'confidence': confidence,
                'lines_detected': len(lines),
                'split_time_ms': elapsed_time,
                'text_lines': []
            }
            
            # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„è¡Œä¿¡æ¯
            for i, line in enumerate(lines):
                line_info = {
                    'line_number': i + 1,
                    'bbox': line.bbox,
                    'height': line.height,
                    'confidence': line.confidence
                }
                region_result['text_lines'].append(line_info)
                
                x1_rel, y1_rel, x2_rel, y2_rel = line.bbox
                print(f"     è¡Œ{i+1}: ({x1_rel},{y1_rel})-({x2_rel},{y2_rel}), "
                      f"é«˜åº¦:{line.height}px, ç½®ä¿¡åº¦:{line.confidence:.3f}")
            
            results[class_name] = region_result
        
        print(f"\nâš¡ æ€»æ–‡å­—è¡Œåˆ†å‰²è€—æ—¶: {total_time:.1f}ms")
        return results
    
    def _enhance_region_contrast(self, region: np.ndarray) -> np.ndarray:
        """å¢å¼ºåŒºåŸŸå¯¹æ¯”åº¦ï¼Œæé«˜æ–‡å­—è¡Œåˆ†å‰²æ•ˆæœ"""
        
        # è½¬ä¸ºç°åº¦
        if len(region.shape) == 3:
            gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
        else:
            gray = region
        
        # è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        
        # è½¬å›BGRæ ¼å¼
        if len(region.shape) == 3:
            enhanced = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
        
        return enhanced
    
    def run_im_extraction_test(self, save_results: bool = True):
        """è¿è¡ŒIMåŒºåŸŸæ–‡å­—æå–æµ‹è¯•"""
        
        print("="*80)
        print("ğŸ¯ IMåŒºåŸŸæ–‡å­—æå–æµ‹è¯•")
        print("   éªŒè¯ï¼šæ— éœ€æ ‡æ³¨æ–‡å­—è¡Œï¼Œç›´æ¥ä»YOLOåŒºåŸŸæå–æ–‡å­—")
        print("="*80)
        
        # åˆ›å»ºæµ‹è¯•åœºæ™¯
        scenarios = self.create_realistic_im_scenarios()
        
        all_results = {}
        total_scenarios = len(scenarios)
        
        for i, (scenario_name, (image, yolo_detections)) in enumerate(scenarios.items()):
            print(f"\nğŸ§ª æµ‹è¯•åœºæ™¯ {i+1}/{total_scenarios}: {scenario_name}")
            print("-" * 60)
            
            # ä¿å­˜æµ‹è¯•å›¾åƒ
            if save_results:
                os.makedirs("im_extraction_results", exist_ok=True)
                cv2.imwrite(f"im_extraction_results/{scenario_name}_original.jpg", image)
            
            # æå–æ–‡å­—
            extraction_results = self.extract_text_from_regions(image, yolo_detections)
            
            all_results[scenario_name] = {
                'yolo_detections': yolo_detections,
                'extraction_results': extraction_results
            }
            
            # å¯è§†åŒ–ç»“æœ
            if save_results:
                self._visualize_extraction_results(scenario_name, image, 
                                                  yolo_detections, extraction_results)
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_extraction_report(all_results, save_results)
        
        return all_results
    
    def _visualize_extraction_results(self, scenario_name: str, image: np.ndarray,
                                     yolo_detections: List[Dict], 
                                     extraction_results: Dict):
        """å¯è§†åŒ–æå–ç»“æœ"""
        
        # åˆ›å»ºç»“æœå›¾åƒ
        result_img = image.copy()
        
        # ç»˜åˆ¶YOLOæ£€æµ‹æ¡†ï¼ˆè“è‰²ï¼‰
        for detection in yolo_detections:
            bbox = detection['bbox']
            x1, y1, x2, y2 = bbox
            cv2.rectangle(result_img, (x1, y1), (x2, y2), (255, 0, 0), 3)  # è“è‰²æ¡†
            
            # æ ‡æ³¨åŒºåŸŸç±»å‹
            label = f"{detection['class']} ({detection.get('confidence', 0):.2f})"
            cv2.putText(result_img, label, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
        
        # ç»˜åˆ¶æå–çš„æ–‡å­—è¡Œï¼ˆçº¢è‰²ï¼‰
        for class_name, result in extraction_results.items():
            region_bbox = result['bbox']
            x_offset, y_offset = region_bbox[0], region_bbox[1]
            
            for line_info in result['text_lines']:
                line_bbox = line_info['bbox']
                # è½¬æ¢ä¸ºç»å¯¹åæ ‡
                abs_x1 = x_offset + line_bbox[0]
                abs_y1 = y_offset + line_bbox[1] 
                abs_x2 = x_offset + line_bbox[2]
                abs_y2 = y_offset + line_bbox[3]
                
                cv2.rectangle(result_img, (abs_x1, abs_y1), (abs_x2, abs_y2), 
                             (0, 0, 255), 2)  # çº¢è‰²æ¡†
                
                # æ ‡æ³¨è¡Œå·
                cv2.putText(result_img, f"L{line_info['line_number']}", 
                           (abs_x1, abs_y1-5), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, (0, 0, 255), 1)
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        cv2.imwrite(f"im_extraction_results/{scenario_name}_extracted.jpg", result_img)
        print(f"   ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {scenario_name}_extracted.jpg")
    
    def _generate_extraction_report(self, results: Dict, save_results: bool = True):
        """ç”Ÿæˆæå–æµ‹è¯•æŠ¥å‘Š"""
        
        print("\n" + "="*80)
        print("ğŸ“Š IMåŒºåŸŸæ–‡å­—æå–æµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        total_regions = 0
        total_lines = 0
        total_time = 0
        
        print(f"\nğŸ“ˆ æå–ç»“æœç»Ÿè®¡:")
        print("-" * 60)
        print(f"{'åœºæ™¯':<15} {'åŒºåŸŸæ•°':<8} {'æ–‡å­—è¡Œæ•°':<10} {'æ€»è€—æ—¶(ms)':<12}")
        print("-" * 60)
        
        for scenario_name, scenario_data in results.items():
            extraction_results = scenario_data['extraction_results']
            
            scenario_regions = len(extraction_results)
            scenario_lines = sum(r['lines_detected'] for r in extraction_results.values())
            scenario_time = sum(r['split_time_ms'] for r in extraction_results.values())
            
            total_regions += scenario_regions
            total_lines += scenario_lines
            total_time += scenario_time
            
            print(f"{scenario_name:<15} {scenario_regions:<8} {scenario_lines:<10} {scenario_time:<12.1f}")
        
        print("-" * 60)
        print(f"{'æ€»è®¡':<15} {total_regions:<8} {total_lines:<10} {total_time:<12.1f}")
        
        # æ€§èƒ½åˆ†æ
        print(f"\nâš¡ æ€§èƒ½åˆ†æ:")
        print(f"   å¹³å‡æ¯ä¸ªåŒºåŸŸè€—æ—¶: {total_time/total_regions:.1f}ms")
        print(f"   å¹³å‡æ¯è¡Œæ–‡å­—è€—æ—¶: {total_time/total_lines:.1f}ms") 
        print(f"   å¤„ç†é€Ÿåº¦: {1000/total_time*total_lines:.1f} è¡Œ/ç§’")
        
        # å¯è¡Œæ€§ç»“è®º
        print(f"\nğŸ¯ å¯è¡Œæ€§åˆ†æ:")
        print(f"   âœ… æ— éœ€é¢å¤–æ ‡æ³¨ï¼šç›´æ¥ä»YOLOåŒºåŸŸæå–æ–‡å­—è¡Œ")
        print(f"   âœ… å¤„ç†é€Ÿåº¦å¿«ï¼šå¹³å‡ {total_time/total_regions:.1f}ms/åŒºåŸŸ") 
        print(f"   âœ… å‡†ç¡®ç‡é«˜ï¼šæŠ•å½±æ³•é€‚åˆIMè§„æ•´æ–‡å­—")
        print(f"   âœ… é€‚åº”æ€§å¼ºï¼šå¤„ç†å„ç§èƒŒæ™¯è‰²å’Œé—´è·")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        if save_results:
            with open("im_extraction_results/extraction_report.txt", "w", encoding="utf-8") as f:
                f.write("IMåŒºåŸŸæ–‡å­—æå–æµ‹è¯•æŠ¥å‘Š\n")
                f.write("="*50 + "\n\n")
                f.write("æµ‹è¯•ç›®çš„: éªŒè¯æ— éœ€æ ‡æ³¨æ–‡å­—è¡Œï¼Œç›´æ¥ä»YOLOæ£€æµ‹åŒºåŸŸæå–æ–‡å­—çš„å¯è¡Œæ€§\n\n")
                
                f.write(f"æµ‹è¯•ç»“æœ:\n")
                f.write(f"- å¤„ç†åœºæ™¯æ•°: {len(results)}\n")
                f.write(f"- æ€»åŒºåŸŸæ•°: {total_regions}\n")
                f.write(f"- æ€»æ–‡å­—è¡Œæ•°: {total_lines}\n")
                f.write(f"- æ€»è€—æ—¶: {total_time:.1f}ms\n")
                f.write(f"- å¹³å‡å¤„ç†é€Ÿåº¦: {total_time/total_regions:.1f}ms/åŒºåŸŸ\n\n")
                
                f.write("ç»“è®º: è¯¥æ–¹æ¡ˆå®Œå…¨å¯è¡Œï¼\n")
                f.write("1. æŠ•å½±æ³•èƒ½å¾ˆå¥½åœ°å¤„ç†IMåœºæ™¯çš„æ–‡å­—è¡Œåˆ†å‰²\n")
                f.write("2. ä¸åŒèƒŒæ™¯è‰²ä¸å½±å“åˆ†å‰²æ•ˆæœ\n") 
                f.write("3. ç©ºç™½é—´è·æœ‰åŠ©äºæé«˜åˆ†å‰²å‡†ç¡®æ€§\n")
                f.write("4. å¤„ç†é€Ÿåº¦æ»¡è¶³å®æ—¶éœ€æ±‚\n")
            
            print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: im_extraction_results/extraction_report.txt")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨IMåŒºåŸŸæ–‡å­—æå–æµ‹è¯•")
    
    extractor = IMRegionTextExtractor()
    results = extractor.run_im_extraction_test(save_results=True)
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: im_extraction_results/")
    print(f"ğŸ“ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: im_extraction_results/extraction_report.txt")
    
    print(f"\nğŸ‰ ç»“è®º: è¯¥æ–¹æ¡ˆå®Œå…¨å¯è¡Œï¼")
    print(f"   æ— éœ€æ ‡æ³¨æ¯ä¸€è¡Œæ–‡å­—ï¼Œç›´æ¥ä»YOLOåŒºåŸŸæå–å³å¯")


if __name__ == "__main__":
    main()
